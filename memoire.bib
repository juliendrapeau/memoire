@inproceedings{aaronsonComputationalComplexityLinear2011,
  title = {The Computational Complexity of Linear Optics},
  booktitle = {Proceedings of the Forty-Third Annual {{ACM}} Symposium on {{Theory}} of Computing},
  author = {Aaronson, Scott and Arkhipov, Alex},
  year = {2011},
  month = jun,
  pages = {333--342},
  doi = {10.1145/1993636.1993682},
  abstract = {We give new evidence that quantum computers -- moreover, rudimentary quantum computers built entirely out of linear-optical elements -- cannot be efficiently simulated by classical computers. In particular, we define a model of computation in which identical photons are generated, sent through a linear-optical network, then nonadaptively measured to count the number of photons in each mode. This model is not known or believed to be universal for quantum computation, and indeed, we discuss the prospects for realizing the model using current technology. On the other hand, we prove that the model is able to solve sampling problems and search problems that are classically intractable under plausible assumptions. Our first result says that, if there exists a polynomial-time classical algorithm that samples from the same probability distribution as a linear-optical network, then P\#P=BPPNP, and hence the polynomial hierarchy collapses to the third level. Unfortunately, this result assumes an extremely accurate simulation.Our main result suggests that even an approximate or noisy classical simulation would already imply a collapse of the polynomial hierarchy. For this, we need two unproven conjectures: the Permanent-of-Gaussians Conjecture, which says that it is \#P-hard to approximate the permanent of a matrix A of independent N(0,1) Gaussian entries, with high probability over A; and the Permanent Anti-Concentration Conjecture, which says that {\textbar}Per(A){\textbar}\&gt;={\textsurd}(n!)poly(n) with high probability over A. We present evidence for these conjectures, both of which seem interesting even apart from our application.This paper does not assume knowledge of quantum optics. Indeed, part of its goal is to develop the beautiful theory of noninteracting bosons underlying our model, and its connection to the permanent function, in a self-contained way accessible to theoretical computer scientists.},
  isbn = {978-1-4503-0691-1}
}

@incollection{aaronsonQuantumApproximateCounting2020,
  title = {Quantum {{Approximate Counting}}, {{Simplified}}},
  booktitle = {2020 {{Symposium}} on {{Simplicity}} in {{Algorithms}}},
  author = {Aaronson, Scott and Rall, Patrick},
  year = {2020},
  pages = {24--32},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9781611976014.5},
  abstract = {In 1998, Brassard, H{\o}yer, Mosca, and Tapp (BHMT) gave a quantum algorithm for approximate counting. Given a list of N items, K of them marked, their algorithm estimates K to within relative error âˆŠ by making only  queries. Although this speedup is of ``Grover'' type, the BHMT algorithm has the curious feature of relying on the Quantum Fourier Transform (QFT), more commonly associated with Shor's algorithm. Is this necessary? This paper presents a simplified algorithm, which we prove achieves the same query complexity using Grover iterations only. We also generalize this to a QFT-free algorithm for amplitude estimation. Related approaches to approximate counting were sketched previously by Grover, Abrams and Williams, Suzuki et al., and Wie (the latter two as we were writing this paper), but in all cases without rigorous analysis.}
}

@article{abramsonHailfinderBayesianSystem1996,
  title = {Hailfinder: {{A Bayesian}} System for Forecasting Severe Weather},
  shorttitle = {Hailfinder},
  author = {Abramson, Bruce and Brown, John and Edwards, Ward and Murphy, Allan and Winkler, Robert L.},
  year = {1996},
  month = mar,
  journal = {International Journal of Forecasting},
  volume = {12},
  number = {1},
  pages = {57--71},
  issn = {0169-2070},
  doi = {10.1016/0169-2070(95)00664-8},
  abstract = {Hailfinder is a Bayesian system that combines meteorological data and model with expert judgment, based on both experience and physical understanding, to forecast severe weather in Northeastern Colorado. The system is based on a model, known as a belief network (BN), that has recently emerged as the basis of some powerful intelligent systems. Hailfinder is the first such system to apply these Bayesian models in the realm of meteorology, a field that has served as the basis of many past investigations of probabilistic forecasting. The design of Hailfinder provides a variety of insights to designers of other BN-based systems, regardless of their fields of application.}
}

@inproceedings{achlioptasPhaseTransition1ink2001,
  title = {The Phase Transition in 1-in-k {{SAT}} and {{NAE}} 3-{{SAT}}},
  booktitle = {Proceedings of the Twelfth Annual {{ACM-SIAM}} Symposium on {{Discrete}} Algorithms},
  author = {Achlioptas, Dimitris and Chtcherba, Arthur and Istrate, Gabriel and Moore, Cristopher},
  year = {2001},
  month = jan,
  pages = {721--722},
  isbn = {978-0-89871-490-6}
}

@article{agrawalPRIMES2004,
  title = {{{PRIMES Is}} in {{P}}},
  author = {Agrawal, Manindra and Kayal, Neeraj and Saxena, Nitin},
  year = {2004},
  journal = {Annals of Mathematics},
  volume = {160},
  number = {2},
  eprint = {3597229},
  eprinttype = {jstor},
  pages = {781--793},
  publisher = {Annals of Mathematics},
  issn = {0003-486X},
  url = {https://www.jstor.org/stable/3597229},
  abstract = {We present an unconditional deterministic polynomial-time algorithm that determines whether an input number is prime or composite.}
}

@article{albashAdiabaticQuantumComputation2018,
  title = {Adiabatic Quantum Computation},
  author = {Albash, Tameem and Lidar, Daniel A.},
  year = {2018},
  month = jan,
  journal = {Reviews of Modern Physics},
  volume = {90},
  number = {1},
  pages = {015002},
  publisher = {American Physical Society},
  doi = {10.1103/RevModPhys.90.015002},
  abstract = {Adiabatic quantum computing (AQC) started as an approach to solving optimization problems and has evolved into an important universal alternative to the standard circuit model of quantum computing, with deep connections to both classical and quantum complexity theory and condensed matter physics. This review gives an account of the major theoretical developments in the field, while focusing on the closed-system setting. The review is organized around a series of topics that are essential to an understanding of the underlying principles of AQC, its algorithmic accomplishments and limitations, and its scope in the more general setting of computational complexity theory. Several variants are presented of the adiabatic theorem, the cornerstone of AQC, and examples are given of explicit AQC algorithms that exhibit a quantum speedup. An overview of several proofs of the universality of AQC and related Hamiltonian quantum complexity theory is given. Considerable space is devoted to stoquastic AQC, the setting of most AQC work to date, where obstructions to success and their possible resolutions are discussed.}
}

@article{altshulerAndersonLocalizationMakes2010,
  title = {Anderson Localization Makes Adiabatic Quantum Optimization Fail},
  author = {Altshuler, Boris and Krovi, Hari and Roland, J{\'e}r{\'e}mie},
  year = {2010},
  month = jul,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {107},
  number = {28},
  pages = {12446--12450},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1002116107},
  abstract = {Understanding NP-complete problems is a central topic in computer science (NP stands for nondeterministic polynomial time). This is why adiabatic quantum optimization has attracted so much attention, as it provided a new approach to tackle NP-complete problems using a quantum computer. The efficiency of this approach is limited by small spectral gaps between the ground and excited states of the quantum computer's Hamiltonian. We show that the statistics of the gaps can be analyzed in a novel way, borrowed from the study of quantum disordered systems in statistical mechanics. It turns out that due to a phenomenon similar to Anderson localization, exponentially small gaps appear close to the end of the adiabatic algorithm for large random instances of NP-complete problems. This implies that unfortunately, adiabatic quantum optimization fails: The system gets trapped in one of the numerous local minima.}
}

@article{aminConsistencyAdiabaticTheorem2009,
  title = {Consistency of the {{Adiabatic Theorem}}},
  author = {Amin, M. H. S.},
  year = {2009},
  month = jun,
  journal = {Physical Review Letters},
  volume = {102},
  number = {22},
  pages = {220401},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.102.220401},
  abstract = {The adiabatic theorem provides the basis for the adiabatic model of quantum computation. Recently the conditions required for the adiabatic theorem to hold have become a subject of some controversy. Here we show that the reported violations of the adiabatic theorem all arise from resonant transitions between energy levels. In the absence of fast driven oscillations the traditional adiabatic theorem holds. Implications for adiabatic quantum computation are discussed.}
}

@article{anschuetzQuantumVariationalAlgorithms2022,
  title = {Quantum Variational Algorithms Are Swamped with Traps},
  author = {Anschuetz, Eric R. and Kiani, Bobak T.},
  year = {2022},
  month = dec,
  journal = {Nature Communications},
  volume = {13},
  number = {1},
  pages = {7760},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-35364-5},
  abstract = {One of the most important properties of classical neural networks is how surprisingly trainable they are, though their training algorithms typically rely on optimizing complicated, nonconvex loss functions. Previous results have shown that unlike the case in classical neural networks, variational quantum models are often not trainable. The most studied phenomenon is the onset of barren plateaus in the training landscape of these quantum models, typically when the models are very deep. This focus on barren plateaus has made the phenomenon almost synonymous with the trainability of quantum models. Here, we show that barren plateaus are only a part of the story. We prove that a wide class of variational quantum models---which are shallow, and exhibit no barren plateaus---have only a superpolynomially small fraction of local minima within any constant energy from the global minimum, rendering these models untrainable if no good initial guess of the optimal parameters is known. We also study the trainability of variational quantum algorithms from a statistical query framework, and show that noisy optimization of a wide variety of quantum models is impossible with a sub-exponential number of queries. Finally, we numerically confirm our results on a variety of problem instances. Though we exclude a wide variety of quantum algorithms here, we give reason for optimism for certain classes of variational algorithms and discuss potential ways forward in showing the practical utility of such algorithms.}
}

@inproceedings{audemardPredictingLearntClauses2009,
  title = {Predicting Learnt Clauses Quality in Modern {{SAT}} Solvers},
  booktitle = {Proceedings of the 21st {{International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Audemard, Gilles and Simon, Laurent},
  year = {2009},
  month = jul,
  pages = {399--404},
  abstract = {Beside impressive progresses made by SAT solvers over the last ten years, only few works tried to understand why Conflict Directed Clause Learning algorithms (CDCL) are so strong and efficient on most industrial applications. We report in this work a key observation of CDCL solvers behavior on this family of benchmarks and explain it by an unsuspected side effect of their particular Clause Learning scheme. This new paradigm allows us to solve an important, still open, question: How to designing a fast, static, accurate, and predictive measure of new learnt clauses pertinence. Our paper is followed by empirical evidences that show how our new learning scheme improves state-of-the art results by an order of magnitude on both SAT and UNSAT industrial problems.}
}

@article{bakerMethodesCalculAvec2021,
  title = {M{\'e}thodes de Calcul Avec R{\'e}seaux de Tenseurs En Physique},
  author = {Baker, Thomas E. and Desrosiers, Samuel and Tremblay, Maxime and Thompson, Martin P.},
  year = {2021},
  month = apr,
  journal = {Canadian Journal of Physics},
  volume = {99},
  number = {4},
  pages = {207--221},
  publisher = {NRC Research Press},
  issn = {0008-4204},
  doi = {10.1139/cjp-2019-0611},
  abstract = {R{\'e}sum{\'e} Cet article se veut un survol des r{\'e}seaux de tenseurs et s'adresse aux d{\'e}butants en la mati{\`e}re. Nous y mettons l'accent sur les outils n{\'e}cessaires {\`a} l'impl{\'e}mentation concr{\`e}te d'algorithmes. Quatre op{\'e}rations de base (remodelage, permutation d'indices, contraction et d{\'e}composition) qui sont couramment utilis{\'e}es dans les algorithmes de r{\'e}seaux de tenseurs y sont d{\'e}crites. Y seront aussi couverts la notation diagrammatique, intrication, les {\'e}tats en produit de matrices (MPS), les op{\'e}rateurs en produit de matrices (MPO), {\'e}tat projet{\'e} de paires intriqu{\'e}es (PEPS), l'approche par renormalisation d'enchev{\^e}trement multi-{\'e}chelle (MERA), la d{\'e}cimation par bloc d'{\'e}volution temporelle (TEBD) et le groupe de renormalisation de tenseurs (TRG).}
}

@inproceedings{balutaQuantitativeVerificationNeural2019,
  title = {Quantitative {{Verification}} of {{Neural Networks}} and {{Its Security Applications}}},
  booktitle = {Proceedings of the 2019 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  author = {Baluta, Teodora and Shen, Shiqi and Shinde, Shweta and Meel, Kuldeep S. and Saxena, Prateek},
  year = {2019},
  month = nov,
  pages = {1249--1264},
  doi = {10.1145/3319535.3354245},
  abstract = {Neural networks are increasingly employed in safety-critical domains. This has prompted interest in verifying or certifying logically encoded properties of neural networks. Prior work has largely focused on checking existential properties, wherein the goal is to check whether there exists any input that violates a given property of interest. However, neural network training is a stochastic process, and many questions arising in their analysis require probabilistic and quantitative reasoning, i.e., estimating how many inputs satisfy a given property. To this end, our paper proposes a novel and principled framework to quantitative verification of logical properties specified over neural networks. Our framework is the first to provide PAC-style soundness guarantees, in that its quantitative estimates are within a controllable and bounded error from the true count. We instantiate our algorithmic framework by building a prototype tool called NPAQ that enables checking rich properties over binarized neural networks. We show how emerging security analyses can utilize our framework in 3 applications: quantifying robustness to adversarial inputs, efficacy of trojan attacks, and fairness/bias of given neural networks.},
  isbn = {978-1-4503-6747-9}
}

@article{barthelClusteringAnalysisGroundstate2004,
  title = {Clustering Analysis of the Ground-State Structure of the Vertex-Cover Problem},
  author = {Barthel, Wolfgang and Hartmann, Alexander K.},
  year = {2004},
  month = dec,
  journal = {Physical Review E},
  volume = {70},
  number = {6},
  pages = {066120},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.70.066120},
  abstract = {Vertex cover is one of the classical NP-complete problems in theoretical computer science. A vertex cover of a graph is a subset of vertices such that for each edge at least one of the two endpoints is contained in the subset. When studied on Erd{\"o}s-R{\'e}nyi random graphs (with connectivity {$c$}) one observes a threshold behavior: In the thermodynamic limit the size of the minimal vertex cover is independent of the specific graph. Recent analytical studies show that on the phase boundary, for small connectivities {$c<e$}, the system is replica symmetric, while for larger connectivities replica symmetry breaking occurs. This change coincides with a change of the typical running time of algorithms from polynomial to exponential. To understand the reasons for this behavior and to compare with the analytical results, we numerically analyze the structure of the solution landscape. For this purpose, we have also developed an algorithm, which allows the calculation of the backbone, without the need to enumerate all solutions. We study exact solutions found with a branch-and-bound algorithm as well as configurations obtained via a Monte Carlo simulation. We analyze the cluster structure of the solution landscape by direct clustering of the states, by analyzing the eigenvalue spectrum of correlation matrices and by using a hierarchical clustering method. All results are compatible with a change at {$c$}={$e$}. For small connectivities, the solutions are collected in a finite small number of clusters, while the number of clusters diverges slowly with system size for larger connectivities and replica symmetry breaking, but not one-step replica symmetry breaking (1-RSB) occurs.}
}

@inproceedings{bartschiGroverMixersQAOA2020,
  title = {Grover {{Mixers}} for {{QAOA}}: {{Shifting Complexity}} from {{Mixer Design}} to {{State Preparation}}},
  shorttitle = {Grover {{Mixers}} for {{QAOA}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Quantum Computing}} and {{Engineering}} ({{QCE}})},
  author = {B{\"a}rtschi, Andreas and Eidenbenz, Stephan},
  year = {2020},
  month = oct,
  pages = {72--82},
  doi = {10.1109/QCE49297.2020.00020},
  abstract = {We propose GM-QAOA, a variation of the Quantum Alternating Operator Ansatz (QAOA) that uses Grover-like selective phase shift mixing operators. GM-QAOA works on any NP optimization problem for which it is possible to efficiently prepare an equal superposition of all feasible solutions; it is designed to perform particularly well for constraint optimization problems, where not all possible variable assignments are feasible solutions. GM-QAOA has the following features: (i) It is not susceptible to Hamiltonian Simulation error (such as Trotterization errors) as its operators can be implemented exactly using standard gate sets and (ii) Solutions with the same objective value are always sampled with the same amplitude. We illustrate the potential of GM-QAOA on several optimization problem classes: for permutation-based optimization problems such as the Traveling Salesperson Problem, we present an efficient algorithm to prepare a superposition of all possible permutations of n numbers, defined on O (n 2) qubits; for the hard constraint k-Vertex-Cover problem, and for an application to Discrete Portfolio Rebalancing, we show that GM-QAOA outperforms existing QAOA approaches.}
}

@misc{biamonteTensorNetworksNutshell2017,
  title = {Tensor {{Networks}} in a {{Nutshell}}},
  author = {Biamonte, Jacob and Bergholm, Ville},
  year = {2017},
  month = jul,
  number = {arXiv:1708.00006},
  eprint = {1708.00006},
  primaryclass = {quant-ph},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1708.00006},
  abstract = {Tensor network methods are taking a central role in modern quantum physics and beyond. They can provide an efficient approximation to certain classes of quantum states, and the associated graphical language makes it easy to describe and pictorially reason about quantum circuits, channels, protocols, open systems and more. Our goal is to explain tensor networks and some associated methods as quickly and as painlessly as possible. Beginning with the key definitions, the graphical tensor network language is presented through examples. We then provide an introduction to matrix product states. We conclude the tutorial with tensor contractions evaluating combinatorial counting problems. The first one counts the number of solutions for Boolean formulae, whereas the second is Penrose's tensor contraction algorithm, returning the number of \$3\$-edge-colorings of \$3\$-regular planar graphs.},
  archiveprefix = {arXiv}
}

@book{biereHandbookSatisfiability2009,
  title = {Handbook of {{Satisfiability}}},
  shorttitle = {Handbook of {{Satisfiability}}},
  author = {Biere, Armin and Heule, Marijn and {van Maaren}, Hans and Walsh, Toby},
  year = {2009},
  month = jan,
  publisher = {IOS Press},
  abstract = {'Satisfiability (SAT) related topics have attracted researchers from various disciplines: logic, applied areas such as planning, scheduling, operations research and combinatorial optimization, but also theoretical issues on the theme of complexity and much more, they all are connected through SAT. My personal interest in SAT stems from actual solving: The increase in power of modern SAT solvers over the past 15 years has been phenomenal. It has become the key enabling technology in automated verification of both computer hardware and software. Bounded Model Checking (BMC) of computer hardware is now probably the most widely used model checking technique. The counterexamples that it finds are just satisfying instances of a Boolean formula obtained by unwinding to some fixed depth a sequential circuit and its specification in linear temporal logic. Extending model checking to software verification is a much more difficult problem on the frontier of current research. One promising approach for languages like C with finite word-length integers is to use the same idea as in BMC but with a decision procedure for the theory of bit-vectors instead of SAT. All decision procedures for bit-vectors that I am familiar with ultimately make use of a fast SAT solver to handle complex formulas. Decision procedures for more complicated theories, like linear real and integer arithmetic, are also used in program verification. Most of them use powerful SAT solvers in an essential way. Clearly, efficient SAT solving is a key technology for 21st century computer science. I expect this collection of papers on all theoretical and practical aspects of SAT solving will be extremely useful to both students and researchers and will lead to many further advances in the field.' Edmund Clarke (FORE Systems University Professor of Computer Science and Professor of Electrical and Computer Engineering at Carnegie Mellon University)},
  isbn = {978-1-58603-929-5}
}

@article{bittelTrainingVariationalQuantum2021,
  title = {Training {{Variational Quantum Algorithms Is NP-Hard}}},
  author = {Bittel, Lennart and Kliesch, Martin},
  year = {2021},
  month = sep,
  journal = {Physical Review Letters},
  volume = {127},
  number = {12},
  pages = {120502},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.127.120502},
  abstract = {Variational quantum algorithms are proposed to solve relevant computational problems on near term quantum devices. Popular versions are variational quantum eigensolvers and quantum approximate optimization algorithms that solve ground state problems from quantum chemistry and binary optimization problems, respectively. They are based on the idea of using a classical computer to train a parametrized quantum circuit. We show that the corresponding classical optimization problems are NP-hard. Moreover, the hardness is robust in the sense that, for every polynomial time algorithm, there are instances for which the relative error resulting from the classical optimization problem can be arbitrarily large assuming that P{$\neq$}NP. Even for classically tractable systems composed of only logarithmically many qubits or free fermions, we show the optimization to be NP-hard. This elucidates that the classical optimization is intrinsically hard and does not merely inherit the hardness from the ground state problem. Our analysis shows that the training landscape can have many far from optimal persistent local minima This means gradient and higher order descent algorithms will generally converge to far from optimal solutions.}
}

@article{blekosReviewQuantumApproximate2024,
  title = {A Review on {{Quantum Approximate Optimization Algorithm}} and Its Variants},
  author = {Blekos, Kostas and Brand, Dean and Ceschini, Andrea and Chou, Chiao-Hui and Li, Rui-Hao and Pandya, Komal and Summer, Alessandro},
  year = {2024},
  month = jun,
  journal = {Physics Reports},
  series = {A Review on {{Quantum Approximate Optimization Algorithm}} and Its Variants},
  volume = {1068},
  pages = {1--66},
  issn = {0370-1573},
  doi = {10.1016/j.physrep.2024.03.002},
  abstract = {The Quantum Approximate Optimization Algorithm (QAOA) is a highly promising variational quantum algorithm that aims to solve combinatorial optimization problems that are classically intractable. This comprehensive review offers an overview of the current state of QAOA, encompassing its performance analysis in diverse scenarios, its applicability across various problem instances, and considerations of hardware-specific challenges such as error susceptibility and noise resilience. Additionally, we conduct a comparative study of selected QAOA extensions and variants, while exploring future prospects and directions for the algorithm. We aim to provide insights into key questions about the algorithm, such as whether it can outperform classical algorithms and under what circumstances it should be used. Towards this goal, we offer specific practical points in a form of a short guide.},
}

@article{bornBeweisAdiabatensatzes1928,
  title = {{Beweis des Adiabatensatzes}},
  author = {Born, M. and Fock, V.},
  year = {1928},
  month = mar,
  journal = {Zeitschrift f{\"u}r Physik},
  volume = {51},
  number = {3},
  pages = {165--180},
  issn = {0044-3328},
  doi = {10.1007/BF01343193},
  abstract = {Der Adiabatensatz in der neuen Quantenmechanik wird f{\"u}r den Fall des Punktspektrums in mathematisch strenger Weise bewiesen, wobei er sich auch bei einer vor{\"u}bergehenden Entartung des mechanischen Systems als g{\"u}ltig erweist.}
}

@article{boulandComplexityVerificationQuantum2019,
  title = {On the Complexity and Verification of Quantum Random Circuit Sampling},
  author = {Bouland, Adam and Fefferman, Bill and Nirkhe, Chinmay and Vazirani, Umesh},
  year = {2019},
  month = feb,
  journal = {Nature Physics},
  volume = {15},
  number = {2},
  pages = {159--163},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/s41567-018-0318-2},
  abstract = {A critical milestone on the path to useful quantum computers is the demonstration of a quantum computation that is prohibitively hard for classical computers---a task referred to as quantum supremacy. A leading near-term candidate is sampling from the probability distributions of randomly chosen quantum circuits, which we call random circuit sampling (RCS). RCS was defined with experimental realizations in mind, leaving its computational hardness unproven. Here we give strong complexity-theoretic evidence of classical hardness of RCS, placing it on par with the best theoretical proposals for supremacy. Specifically, we show that RCS satisfies an average-case hardness condition, which is critical to establishing computational hardness in the presence of experimental noise. In addition, it follows from known results that RCS also satisfies an anti-concentration property, namely that errors in estimating output probabilities are small with respect to the probabilities themselves. This makes RCS the first proposal for quantum supremacy with both of these properties. Finally, we also give a natural condition under which an existing statistical measure, cross-entropy, verifies RCS, as well as describe a new verification measure that in some formal sense maximizes the information gained from experimental samples.}
}

@incollection{brassardQuantumAmplitudeAmplification2002,
  title = {Quantum Amplitude Amplification and Estimation},
  booktitle = {Quantum Computation and Information ({{Washington}}, {{DC}}, 2000)},
  author = {Brassard, Gilles and H{\o}yer, Peter and Mosca, Michele and Tapp, Alain},
  year = {2002},
  volume = {305},
  pages = {53--74},
  publisher = {Amer. Math. Soc., Providence, RI},
  doi = {10.1090/conm/305/05215},
  isbn = {978-0-8218-2140-4},
  mrnumber = {1947332}
}

@article{bridgemanHandwavingInterpretiveDance2017,
  title = {Hand-Waving and Interpretive Dance: An Introductory Course on Tensor Networks},
  shorttitle = {Hand-Waving and Interpretive Dance},
  author = {Bridgeman, Jacob C and Chubb, Christopher T},
  year = {2017},
  month = may,
  journal = {Journal of Physics A: Mathematical and Theoretical},
  volume = {50},
  number = {22},
  pages = {223001},
  publisher = {IOP Publishing},
  issn = {1751-8121},
  doi = {10.1088/1751-8121/aa6dc3},
  abstract = {The curse of dimensionality associated with the Hilbert space of spin systems provides a significant obstruction to the study of condensed matter systems. Tensor networks have proven an important tool in attempting to overcome this difficulty in both the numerical and analytic regimes. These notes form the basis for a seven lecture course, introducing the basics of a range of common tensor networks and algorithms. In particular, we cover: introductory tensor network notation, applications to quantum information, basic properties of matrix product states, a classification of quantum phases using tensor networks, algorithms for finding matrix product states, basic properties of projected entangled pair states, and multiscale entanglement renormalisation ansatz states. The lectures are intended to be generally accessible, although the relevance of many of the examples may be lost on students without a background in many-body physics/quantum information. For each lecture, several problems are given, with worked solutions in an ancillary file.}
}

@inproceedings{broderHowHardIt1986,
  title = {How {{Hard}} Is {{It}} to {{Marry}} at {{Random}}? ({{On}} the {{Approximation}} of the {{Permanent}})},
  booktitle = {Proceedings of the {{Eighteenth Annual ACM Symposium}} on {{Theory}} of {{Computing}}},
  author = {Broder, Andrei Z.},
  year = {1986},
  pages = {50--58},
  doi = {10.1145/12130.12136},
  isbn = {0-89791-193-8}
}

@book{carlsonMillenniumPrizeProblems2006,
  title = {The {{Millennium Prize Problems}}},
  author = {Carlson, James A. and Jaffe, Arthur and Wiles, Andrew and Institute, Clay Mathematics and Society, American Mathematical},
  year = {2006},
  publisher = {American Mathematical Soc.},
  abstract = {Guided by the premise that solving some of the world's most important mathematical problems will advance the field, this book offers a fascinating look at the seven unsolved Millennium Prize problems. This work takes the unprecedented approach of describing these important and difficult problems at the professional level. In announcing the seven problems and a US\$7 million prize fund in 2000, the Clay Mathematics Institute emphasized that mathematics still constitutes an openfrontier with important unsolved problems. The descriptions in this book serve the Institute's mission to ``further the beauty, power and universality of mathematical thinking.'' Separate chapters are devoted to each of the seven problems: the Birch and Swinnerton-Dyer Conjecture, the Hodge Conjecture, theNavier-Stokes Equation, the P versus NP Problem, the Poincare Conjecture, the Riemann Hypothesis, and Quantum Yang-Mills Theory. An essay by Jeremy Gray, a well-known expert in the history of mathematics, outlines the history of prize problems in mathematics and shows how some of mathematics' most important discoveries were first revealed in papers submitted for prizes. Numerous photographs of mathematicians who shaped mathematics as it is known today give the text a broad historical appeal.Anyone interested in mathematicians' continued efforts to solve important problems will be fascinated with this text, which places into context the historical dimension of important achievements. Information for our distributors: A co-publication of the AMS and the Clay Mathematics Institute(Cambridge, MA).},
  googlebooks = {7wJIPJ80RdUC},
  isbn = {978-0-8218-3679-8}
}

@article{cerezoVariationalQuantumAlgorithms2021,
  title = {Variational Quantum Algorithms},
  author = {Cerezo, M. and Arrasmith, Andrew and Babbush, Ryan and Benjamin, Simon C. and Endo, Suguru and Fujii, Keisuke and McClean, Jarrod R. and Mitarai, Kosuke and Yuan, Xiao and Cincio, Lukasz and Coles, Patrick J.},
  year = {2021},
  month = sep,
  journal = {Nature Reviews Physics},
  volume = {3},
  number = {9},
  pages = {625--644},
  publisher = {Nature Publishing Group},
  issn = {2522-5820},
  doi = {10.1038/s42254-021-00348-9},
  abstract = {Applications such as simulating complicated quantum systems or solving large-scale linear algebra problems are very challenging for classical computers, owing to the extremely high computational cost. Quantum computers promise a solution, although fault-tolerant quantum computers will probably not be available in the near future. Current quantum devices have serious constraints, including limited numbers of qubits and noise processes that limit circuit depth. Variational quantum algorithms (VQAs), which use a classical optimizer to train a parameterized quantum circuit, have emerged as a leading strategy to address these constraints. VQAs have now been proposed for essentially all applications that researchers have envisaged for quantum computers, and they appear to be the best hope for obtaining quantum advantage. Nevertheless, challenges remain, including the trainability, accuracy and efficiency of VQAs. Here we overview the field of VQAs, discuss strategies to overcome their challenges and highlight the exciting prospects for using them to obtain quantum advantage.}
}

@inproceedings{chakrabortyScalableNearlyUniform2013,
  title = {A {{Scalable}} and {{Nearly Uniform Generator}} of {{SAT Witnesses}}},
  booktitle = {Computer {{Aided Verification}}},
  author = {Chakraborty, Supratik and Meel, Kuldeep S. and Vardi, Moshe Y.},
  year = {2013},
  pages = {608--623},
  publisher = {Springer},
  doi = {10.1007/978-3-642-39799-8_40},
  abstract = {Functional verification constitutes one of the most challenging tasks in the development of modern hardware systems, and simulation-based verification techniques dominate the functional verification landscape. A dominant paradigm in simulation-based verification is directed random testing, where a model of the system is simulated with a set of random test stimuli that are uniformly or near-uniformly distributed over the space of all stimuli satisfying a given set of constraints. Uniform or near-uniform generation of solutions for large constraint sets is therefore a problem of theoretical and practical interest. For Boolean constraints, prior work offered heuristic approaches with no guarantee of performance, and theoretical approaches with proven guarantees, but poor performance in practice. We offer here a new approach with theoretical performance guarantees and demonstrate its practical utility on large constraint sets.},
  isbn = {978-3-642-39799-8}
}

@incollection{cobhamIntrinsicComputationalDifficulty1965,
  title = {The {{Intrinsic Computational Difficulty}} of {{Functions}}},
  booktitle = {Logic, Methodology and Philosophy of Science},
  author = {Cobham, Alan},
  year = {1965},
  pages = {24--30},
  publisher = {North-Holland Pub. Co.}
}

@inproceedings{cookComplexityTheoremprovingProcedures1971,
  title = {The Complexity of Theorem-Proving Procedures},
  booktitle = {Proceedings of the Third Annual {{ACM}} Symposium on {{Theory}} of Computing},
  author = {Cook, Stephen A.},
  year = {1971},
  month = may,
  pages = {151--158},
  doi = {10.1145/800157.805047},
  abstract = {It is shown that any recognition problem solved by a polynomial time-bounded nondeterministic Turing machine can be ``reduced'' to the problem of determining whether a given propositional formula is a tautology. Here ``reduced'' means, roughly speaking, that the first problem can be solved deterministically in polynomial time provided an oracle is available for solving the second. From this notion of reducible, polynomial degrees of difficulty are defined, and it is shown that the problem of determining tautologyhood has the same polynomial degree as the problem of determining whether the first of two given graphs is isomorphic to a subgraph of the second. Other examples are discussed. A method of measuring the complexity of proof procedures for the predicate calculus is introduced and discussed.},
  isbn = {978-1-4503-7464-4}
}

@article{dahllofCountingModels2SAT2005,
  title = {Counting Models for {{2SAT}} and {{3SAT}} Formulae},
  author = {Dahll{\"o}f, Vilhelm and Jonsson, Peter and Wahlstr{\"o}m, Magnus},
  year = {2005},
  month = feb,
  journal = {Theoretical Computer Science},
  volume = {332},
  number = {1},
  pages = {265--291},
  issn = {0304-3975},
  doi = {10.1016/j.tcs.2004.10.037},
  abstract = {We here present algorithms for counting models and max-weight models for 2SAT and 3SAT formulae. They use polynomial space and run in O(1.2561n) and O(1.6737n) time, respectively, where n is the number of variables. This is faster than the previously best algorithms for counting non-weighted models for 2SAT and 3SAT, which run in O(1.3247n) and O(1.6894n) time, respectively. In order to prove these time bounds, we develop new measures of formula complexity, allowing us to conveniently analyze the effects of certain factors with a large impact on the total running time. We also provide an algorithm for the restricted case of separable 2SAT formulae, with fast running times for well-studied input classes. For all three algorithms we present interesting applications, such as computing the permanent of sparse 0/1 matrices.}
}

@article{davisMachineProgramTheoremproving1962,
  title = {A Machine Program for Theorem-Proving},
  author = {Davis, Martin and Logemann, George and Loveland, Donald},
  year = {1962},
  month = jul,
  journal = {Communications of the ACM},
  volume = {5},
  number = {7},
  pages = {394--397},
  issn = {0001-0782},
  doi = {10.1145/368273.368557},
  abstract = {The programming of a proof procedure is discussed in connection with trial runs and possible improvements.}
}

@misc{dudekEfficientContractionLarge2020,
  title = {Efficient {{Contraction}} of {{Large Tensor Networks}} for {{Weighted Model Counting}} through {{Graph Decompositions}}},
  author = {Dudek, Jeffrey M. and {Due{\~n}as-Osorio}, Leonardo and Vardi, Moshe Y.},
  year = {2020},
  month = apr,
  number = {arXiv:1908.04381},
  eprint = {1908.04381},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1908.04381},
  abstract = {Constrained counting is a fundamental problem in artificial intelligence. A promising new algebraic approach to constrained counting makes use of tensor networks, following a reduction from constrained counting to the problem of tensor-network contraction. Contracting a tensor network efficiently requires determining an efficient order to contract the tensors inside the network, which is itself a difficult problem. In this work, we apply graph decompositions to find contraction orders for tensor networks. We prove that finding an efficient contraction order for a tensor network is equivalent to the well-known problem of finding an optimal carving decomposition. Thus memory-optimal contraction orders for planar tensor networks can be found in cubic time. We show that tree decompositions can be used both to find carving decompositions and to factor tensor networks with high-rank, structured tensors. We implement these algorithms on top of state-of-the-art solvers for tree decompositions and show empirically that the resulting weighted model counter is quite effective and useful as part of a portfolio of counters.},
  archiveprefix = {arXiv}
}

@misc{dudekParallelWeightedModel2021,
  title = {Parallel {{Weighted Model Counting}} with {{Tensor Networks}}},
  author = {Dudek, Jeffrey M. and Vardi, Moshe Y.},
  year = {2021},
  month = jun,
  number = {arXiv:2006.15512},
  eprint = {2006.15512},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2006.15512},
  abstract = {A promising new algebraic approach to weighted model counting makes use of tensor networks, following a reduction from weighted model counting to tensor-network contraction. Prior work has focused on analyzing the single-core performance of this approach, and demonstrated that it is an effective addition to the current portfolio of weighted-model-counting algorithms. In this work, we explore the impact of multi-core and GPU use on tensor-network contraction for weighted model counting. To leverage multiple cores, we implement a parallel portfolio of tree-decomposition solvers to find an order to contract tensors. To leverage a GPU, we use TensorFlow to perform the contractions. We compare the resulting weighted model counter on 1914 standard weighted model counting benchmarks and show that it significantly improves the virtual best solver.},
  archiveprefix = {arXiv}
}

@inproceedings{duenas-osorioCountingbasedReliabilityEstimation2017,
  title = {Counting-Based Reliability Estimation for Power-Transmission Grids},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {{Duenas-Osorio}, Leonardo and Meel, Kuldeep and Paredes, Roger and Vardi, Moshe},
  year = {2017},
  month = feb,
  volume = {31},
  pages = {4488--4494},
  doi = {10.1609/aaai.v31i1.11178},
  annotation = {Modern society is increasingly reliant on the functionality of infrastructure facilities and utility services. Consequently, there has been surge of interest in the problem of quantification of system reliability, which is known to be \#P-complete. Reliability also contributes to the resilience of systems, so as to effectively make them bounce back after contingencies. Despite diverse progress, most techniques to estimate system reliability and resilience remain computationally expensive. In this paper, we investigate how recent advances in hashing-based approaches to counting can be exploited to improve computational techniques for system reliability. The primary contribution of this paper is a novel framework, RelNet, that reduces the problem of computing reliability for a given network to counting the number of satisfying assignments of a {$\sum$}11 formula, which is amenable to recent hashing-based techniques developed for counting satisfying assignments of SAT formula. We then apply RelNet to ten real world power-transmission grids across different cities in the U.S. and are able to obtain, to the best of our knowledge, the first theoretically sound a priori estimates of reliability between several pairs of nodes of interest. Such estimates will help managing uncertainty and support rational decision making for community resilience.}
}

@article{dyerMarkovChainsIndependent2000,
  title = {On {{Markov Chains}} for {{Independent Sets}}},
  author = {Dyer, Martin and Greenhill, Catherine},
  year = {2000},
  month = apr,
  journal = {Journal of Algorithms},
  volume = {35},
  number = {1},
  pages = {17--49},
  issn = {0196-6774},
  doi = {10.1006/jagm.1999.1071},
  abstract = {Random independent sets in graphs arise, for example, in statistical physics, in the hardcore model of a gas. In 1997, Luby and Vigoda described a rapidly mixing Markov chain for independent sets, which we refer to as the Luby--Vigoda chain. A new rapidly mixing Markov chain for independent sets is defined in this paper. Using path coupling, we obtain a polynomial upper bound for the mixing time of the new chain for a certain range of values of the parameter {$\lambda$}. This range is wider than the range for which the mixing time of the Luby--Vigoda chain is known to be polynomially bounded. Moreover, the upper bound on the mixing time of the new chain is always smaller than the best known upper bound on the mixing time of the Luby--Vigoda chain for larger values of {$\lambda$} (unless the maximum degree of the graph is 4). An extension of the chain to independent sets in hypergraphs is described. This chain gives an efficient method for approximately counting the number of independent sets of hypergraphs with maximum degree two, or with maximum degree three and maximum edge size three. Finally, we describe a method which allows one, under certain circumstances, to deduce the rapid mixing of one Markov chain from the rapid mixing of another, with the same state space and stationary distribution. This method is applied to two Markov chains for independent sets, a simple insert/delete chain, and the new chain, to show that the insert/delete chain is rapidly mixing for a wider range of values of {$\lambda$} than was previously known.}
}

@article{edmondsPathsTreesFlowers1965,
  title = {Paths, {{Trees}}, and {{Flowers}}},
  author = {Edmonds, Jack},
  year = {1965},
  month = jan,
  journal = {Canadian Journal of Mathematics},
  volume = {17},
  pages = {449--467},
  issn = {0008-414X, 1496-4279},
  doi = {10.4153/CJM-1965-045-4},
  abstract = {A graph G for purposes here is a finite set of elements called vertices and a finite set of elements called edges such that each edge meets exactly two vertices, called the end-points of the edge. An edge is said to join its end-points.A matching in G is a subset of its edges such that no two meet the same vertex. We describe an efficient algorithm for finding in a given graph a matching of maximum cardinality. This problem was posed and partly solved by C. Berge; see Sections 3.7 and 3.8.}
}

@inproceedings{eenExtensibleSATsolver2004,
  title = {An {{Extensible SAT-solver}}},
  booktitle = {Theory and {{Applications}} of {{Satisfiability Testing}}},
  author = {E{\'e}n, Niklas and S{\"o}rensson, Niklas},
  year = {2004},
  pages = {502--518},
  doi = {10.1007/978-3-540-24605-3_37},
  abstract = {In this article, we present a small, complete, and efficient SAT-solver in the style of conflict-driven learning, as exemplified by Chaff. We aim to give sufficient details about implementation to enable the reader to construct his or her own solver in a very short time. This will allow users of SAT-solvers to make domain specific extensions or adaptions of current state-of-the-art SAT-techniques, to meet the needs of a particular application area. The presented solver is designed with this in mind, and includes among other things a mechanism for adding arbitrary boolean constraints. It also supports solving a series of related SAT-problems efficiently by an incremental SAT-interface.},
  isbn = {978-3-540-24605-3}
}

@article{eggerWarmstartingQuantumOptimization2021,
  title = {Warm-Starting Quantum Optimization},
  author = {Egger, Daniel J. and Mare{\v c}ek, Jakub and Woerner, Stefan},
  year = {2021},
  month = jun,
  journal = {Quantum},
  volume = {5},
  pages = {479},
  publisher = {Verein zur F{\"o}rderung des Open Access Publizierens in den Quantenwissenschaften},
  doi = {10.22331/q-2021-06-17-479},
  abstract = {Daniel J. Egger, Jakub Mare{\v c}ek, and Stefan Woerner, Quantum 5, 479 (2021). There is an increasing interest in quantum algorithms for problems of integer programming and combinatorial optimization. Classical solvers for such problems employ relaxations, which replac{\dots}}
}

@misc{farhiQuantumApproximateOptimization2014,
  title = {A {{Quantum Approximate Optimization Algorithm}}},
  author = {Farhi, Edward and Goldstone, Jeffrey and Gutmann, Sam},
  year = {2014},
  month = nov,
  number = {arXiv:1411.4028},
  eprint = {1411.4028},
  primaryclass = {quant-ph},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1411.4028},
  abstract = {We introduce a quantum algorithm that produces approximate solutions for combinatorial optimization problems. The algorithm depends on a positive integer p and the quality of the approximation improves as p is increased. The quantum circuit that implements the algorithm consists of unitary gates whose locality is at most the locality of the objective function whose optimum is sought. The depth of the circuit grows linearly with p times (at worst) the number of constraints. If p is fixed, that is, independent of the input size, the algorithm makes use of efficient classical preprocessing. If p grows with the input size a different strategy is proposed. We study the algorithm as applied to MaxCut on regular graphs and analyze its performance on 2-regular and 3-regular graphs for fixed p. For p = 1, on 3-regular graphs the quantum algorithm always finds a cut that is at least 0.6924 times the size of the optimal cut.},
  archiveprefix = {arXiv}
}

@misc{farhiQuantumApproximateOptimization2020,
  title = {The {{Quantum Approximate Optimization Algorithm Needs}} to {{See}} the {{Whole Graph}}: {{A Typical Case}}},
  shorttitle = {The {{Quantum Approximate Optimization Algorithm Needs}} to {{See}} the {{Whole Graph}}},
  author = {Farhi, Edward and Gamarnik, David and Gutmann, Sam},
  year = {2020},
  month = apr,
  number = {arXiv:2004.09002},
  eprint = {2004.09002},
  primaryclass = {quant-ph},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2004.09002},
  abstract = {The Quantum Approximate Optimization Algorithm can naturally be applied to combinatorial search problems on graphs. The quantum circuit has p applications of a unitary operator that respects the locality of the graph. On a graph with bounded degree, with p small enough, measurements of distant qubits in the state output by the QAOA give uncorrelated results. We focus on finding big independent sets in random graphs with dn/2 edges keeping d fixed and n large. Using the Overlap Gap Property of almost optimal independent sets in random graphs, and the locality of the QAOA, we are able to show that if p is less than a d-dependent constant times log n, the QAOA cannot do better than finding an independent set of size .854 times the optimal for d large. Because the logarithm is slowly growing, even at one million qubits we can only show that the algorithm is blocked if p is in single digits. At higher p the algorithm "sees" the whole graph and we have no indication that performance is limited.},
  archiveprefix = {arXiv}
}

@misc{farhiQuantumComputationAdiabatic2000,
  title = {Quantum {{Computation}} by {{Adiabatic Evolution}}},
  author = {Farhi, Edward and Goldstone, Jeffrey and Gutmann, Sam and Sipser, Michael},
  year = {2000},
  month = jan,
  number = {arXiv:quant-ph/0001106},
  eprint = {quant-ph/0001106},
  publisher = {arXiv},
  doi = {10.48550/arXiv.quant-ph/0001106},
  abstract = {We give a quantum algorithm for solving instances of the satisfiability problem, based on adiabatic evolution. The evolution of the quantum state is governed by a time-dependent Hamiltonian that interpolates between an initial Hamiltonian, whose ground state is easy to construct, and a final Hamiltonian, whose ground state encodes the satisfying assignment. To ensure that the system evolves to the desired final ground state, the evolution time must be big enough. The time required depends on the minimum energy difference between the two lowest states of the interpolating Hamiltonian. We are unable to estimate this gap in general. We give some special symmetric cases of the satisfiability problem where the symmetry allows us to estimate the gap and we show that, in these cases, our algorithm runs in polynomial time.},
  archiveprefix = {arXiv}
}

@article{ferrisPerfectSamplingUnitary2012,
  title = {Perfect Sampling with Unitary Tensor Networks},
  author = {Ferris, Andrew J. and Vidal, Guifre},
  year = {2012},
  month = apr,
  journal = {Physical Review B},
  volume = {85},
  number = {16},
  pages = {165146},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevB.85.165146},
  abstract = {Tensor network states are powerful variational Ans{\"a}tze for many-body ground states of quantum lattice models. The use of Monte Carlo sampling techniques in tensor network approaches significantly reduces the cost of tensor contractions, potentially leading to a substantial increase in computational efficiency. Previous proposals are based on a Markov chain Monte Carlo scheme generated by locally updating configurations and, as such, must deal with equilibration and autocorrelation times, which result in a reduction of efficiency. Here we propose perfect sampling schemes, with vanishing equilibration and autocorrelation times, for unitary tensor networks, namely, tensor networks based on efficiently contractible, unitary quantum circuits, such as unitary versions of the matrix product state (MPS) and tree tensor network (TTN), and the multiscale entanglement renormalization Ansatz (MERA). Configurations are directly sampled according to their probabilities in the wave function, without resorting to a Markov chain process. We consider both complete sampling, involving all the relevant sites of the system, and incomplete sampling, which only involves a subset of those sites and which can result in a dramatic (basis-dependent) reduction of sampling error.}
}

@article{froleyksSATCompetition20202021,
  title = {{{SAT Competition}} 2020},
  author = {Froleyks, Nils and Heule, Marijn and Iser, Markus and J{\"a}rvisalo, Matti and Suda, Martin},
  year = {2021},
  month = dec,
  journal = {Artificial Intelligence},
  volume = {301},
  pages = {103572},
  issn = {0004-3702},
  doi = {10.1016/j.artint.2021.103572},
  abstract = {The SAT Competitions constitute a well-established series of yearly open international algorithm implementation competitions, focusing on the Boolean satisfiability (or propositional satisfiability, SAT) problem. In this article, we provide a detailed account on the 2020 instantiation of the SAT Competition, including the new competition tracks and benchmark selection procedures, overview of solving strategies implemented in top-performing solvers, and a detailed analysis of the empirical data obtained from running the competition.}
}

@article{goldreichComputationalComplexityConceptual2008,
  title = {Computational Complexity: A Conceptual Perspective},
  shorttitle = {Computational Complexity},
  author = {Goldreich, Oded},
  year = {2008},
  month = sep,
  journal = {SIGACT News},
  volume = {39},
  number = {3},
  pages = {35--39},
  issn = {0163-5700},
  doi = {10.1145/1412700.1412710},
  abstract = {This book is rooted in the thesis that complexity theory is extremely rich in conceptual content, and that this contents should be explicitly communicated in expositions and courses on the subject. The desire to provide a corresponding textbook is indeed the motivation for writing the current book and its main governing principle.The book offers a conceptual perspective on complexity theory, and the presentation is designed to highlight this perspective. It is intended mainly for students that wish to learn complexity theory and for educators that intend to teach a course on complexity theory. The book is also intended to promote interest in complexity theory and make it acccessible to general readers with adequate background (which is mainly being comfortable with abstract discussions, definitions and proofs). We expect most readers to have a basic knowledge of algorithms, or at least be fairly comfortable with the notion of an algorithm.The book focuses on several sub-areas of complexity theory (including, e.g., pseudorandomness and probabilistic proof systems). In each case, the exposition starts from the intuitive questions addresses by the sub-area, as embodied in the concepts that it studies. The exposition discusses the fundamental importance of these questions, the choices made in the actual formulation of these questions and notions, the approaches that underly the answers, and the ideas that are embedded in these answers. Our view is that these ({\textbackslash}non-technical") aspects are the core of the field, and the presentation attempts to re ect this view.}
}

@inproceedings{gomesSamplingModelCounting2007,
  title = {From Sampling to Model Counting},
  booktitle = {Proceedings of the 20th International Joint Conference on {{Artifical}} Intelligence},
  author = {Gomes, Carla P. and Hoffmann, Joerg and Sabharwal, Ashish and Selman, Bart},
  year = {2007},
  month = jan,
  pages = {2293--2299},
  abstract = {We introduce a new technique for counting models of Boolean satisfiability problems. Our approach incorporates information obtained from sampling the solution space. Unlike previous approaches, our method does not require uniform or near-uniform samples. It instead converts local search sampling without any guarantees into very good bounds on the model count with guarantees. We give a formal analysis and provide experimental results showing the effectiveness of our approach.}
}

@article{grayHyperoptimizedTensorNetwork2021,
  title = {Hyper-Optimized Tensor Network Contraction},
  author = {Gray, Johnnie and Kourtis, Stefanos},
  year = {2021},
  month = mar,
  journal = {Quantum},
  volume = {5},
  pages = {410},
  publisher = {Verein zur F{\"o}rderung des Open Access Publizierens in den Quantenwissenschaften},
  doi = {10.22331/q-2021-03-15-410},
  abstract = {Johnnie Gray and Stefanos Kourtis, Quantum 5, 410 (2021). Tensor networks represent the state-of-the-art in computational methods across many disciplines, including the classical simulation of quantum many-body systems and quantum circuits. Several{\dots}}
}

@article{grayQuimbPythonPackage2018,
  title = {Quimb: {{A}} Python Package for Quantum Information and Many-Body Calculations},
  shorttitle = {Quimb},
  author = {Gray, Johnnie},
  year = {2018},
  month = sep,
  journal = {Journal of Open Source Software},
  volume = {3},
  number = {29},
  pages = {819},
  issn = {2475-9066},
  doi = {10.21105/joss.00819},
  abstract = {Gray, (2018). quimb: A python package for quantum information and many-body calculations. Journal of Open Source Software, 3(29), 819, https://doi.org/10.21105/joss.00819}
}

@article{hadfieldQuantumApproximateOptimization2019,
  title = {From the {{Quantum Approximate Optimization Algorithm}} to a {{Quantum Alternating Operator Ansatz}}},
  author = {Hadfield, Stuart and Wang, Zhihui and O'Gorman, Bryan and Rieffel, Eleanor G. and Venturelli, Davide and Biswas, Rupak},
  year = {2019},
  month = feb,
  journal = {Algorithms},
  volume = {12},
  number = {2},
  pages = {34},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1999-4893},
  doi = {10.3390/a12020034},
  abstract = {The next few years will be exciting as prototype universal quantum processors emerge, enabling the implementation of a wider variety of algorithms. Of particular interest are quantum heuristics, which require experimentation on quantum hardware for their evaluation and which have the potential to significantly expand the breadth of applications for which quantum computers have an established advantage. A leading candidate is Farhi et al.'s quantum approximate optimization algorithm, which alternates between applying a cost function based Hamiltonian and a mixing Hamiltonian. Here, we extend this framework to allow alternation between more general families of operators. The essence of this extension, the quantum alternating operator ansatz, is the consideration of general parameterized families of unitaries rather than only those corresponding to the time evolution under a fixed local Hamiltonian for a time specified by the parameter. This ansatz supports the representation of a larger, and potentially more useful, set of states than the original formulation, with potential long-term impact on a broad array of application areas. For cases that call for mixing only within a desired subspace, refocusing on unitaries rather than Hamiltonians enables more efficiently implementable mixers than was possible in the original framework. Such mixers are particularly useful for optimization problems with hard constraints that must always be satisfied, defining a feasible subspace, and soft constraints whose violation we wish to minimize. More efficient implementation enables earlier experimental exploration of an alternating operator approach, in the spirit of the quantum approximate optimization algorithm, to a wide variety of approximate optimization, exact optimization, and sampling problems. In addition to introducing the quantum alternating operator ansatz, we lay out design criteria for mixing operators, detail mappings for eight problems, and provide a compendium with brief descriptions of mappings for a diverse array of problems.}
}

@incollection{hemaspaandraPowerSelfReducibilitySelectivity2020,
  title = {The {{Power}} of {{Self-Reducibility}}: {{Selectivity}}, {{Information}}, and {{Approximation}}},
  booktitle = {Complexity and {{Approximation}}: {{In Memory}} of {{Ker-I Ko}}},
  author = {Hemaspaandra, Lane A.},
  year = {2020},
  pages = {19--47},
  publisher = {Springer International Publishing},
  doi = {10.1007/978-3-030-41672-0_3},
  abstract = {This chapter provides a hands-on tutorial on the important technique known as self-reducibility. Through a series of ``Challenge Problems'' that are theorems that the reader will---after being given definitions and tools---try to prove, the tutorial will ask the reader not to read proofs that use self-reducibility, but rather to discover proofs that use self-reducibility. In particular, the chapter will seek to guide the reader to the discovery of proofs of four interesting theorems---whose focus areas range from selectivity to information to approximation---from the literature, whose proofs draw on self-reducibility.},
  isbn = {978-3-030-41672-0}
}

@article{hormoziNonstoquasticHamiltoniansQuantum2017,
  title = {Nonstoquastic {{Hamiltonians}} and Quantum Annealing of an {{Ising}} Spin Glass},
  author = {Hormozi, Layla and Brown, Ethan W. and Carleo, Giuseppe and Troyer, Matthias},
  year = {2017},
  month = may,
  journal = {Physical Review B},
  volume = {95},
  number = {18},
  pages = {184416},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevB.95.184416},
  abstract = {We study the role of Hamiltonian complexity in the performance of quantum annealers. We consider two general classes of annealing Hamiltonians: stoquastic ones, which can be simulated efficiently using the quantum Monte Carlo algorithm, and nonstoquastic ones, which cannot be treated efficiently. We implement the latter by adding antiferromagnetically coupled two-spin driver terms to the traditionally studied transverse-field Ising model, and compare their performance to that of similar stoquastic Hamiltonians with ferromagnetically coupled additional terms. We focus on a model of long-range Ising spin glass as our problem Hamiltonian and carry out the comparison between the annealers by numerically calculating their success probabilities in solving random instances of the problem Hamiltonian in systems of up to 17 spins. We find that, for a small percentage of mostly harder instances, nonstoquastic Hamiltonians greatly outperform their stoquastic counterparts and their superiority persists as the system size grows. We conjecture that the observed improved performance is closely related to the frustrated nature of nonstoquastic Hamiltonians.}
}

@inproceedings{ignatievPySATPythonToolkit2018,
  title = {{{PySAT}}: {{A Python Toolkit}} for {{Prototyping}} with {{SAT Oracles}}},
  shorttitle = {{{PySAT}}},
  booktitle = {Theory and {{Applications}} of {{Satisfiability Testing}} -- {{SAT}} 2018},
  author = {Ignatiev, Alexey and Morgado, Antonio and {Marques-Silva}, Joao},
  year = {2018},
  pages = {428--437},
  doi = {10.1007/978-3-319-94144-8_26},
  abstract = {Boolean satisfiability (SAT) solvers are at the core of efficient approaches for solving a vast multitude of practical problems. Moreover, albeit targeting an NP-complete problem, SAT solvers are increasingly used for tackling problems beyond NP. Despite the success of SAT in practice, modeling with SAT and more importantly implementing SAT-based problem solving solutions is often a difficult and error-prone task. This paper proposes the PySAT toolkit, which enables fast Python-based prototyping using SAT oracles and SAT-related technology. PySAT provides a simple API for working with a few state-of-the-art SAT oracles and also integrates a number of cardinality constraint encodings, all aiming at simplifying the prototyping process. Experimental results presented in the paper show that PySAT-based implementations can be as efficient as those written in a low-level language.},
  isbn = {978-3-319-94144-8}
}

@article{impagliazzoComplexityKSAT2001,
  title = {On the {{Complexity}} of {\emph{K}}-{{SAT}}},
  author = {Impagliazzo, Russell and Paturi, Ramamohan},
  year = {2001},
  month = mar,
  journal = {Journal of Computer and System Sciences},
  volume = {62},
  number = {2},
  pages = {367--375},
  issn = {0022-0000},
  doi = {10.1006/jcss.2000.1727},
  abstract = {The k-SAT problem is to determine if a given k-CNF has a satisfying assignment. It is a celebrated open question as to whether it requires exponential time to solve k-SAT for kâ©¾3. Here exponential time means 2{$\delta$}n for some {$\delta>$}0. In this paper, assuming that, for kâ©¾3, k-SAT requires exponential time complexity, we show that the complexity of k-SAT increases as k increases. More precisely, for kâ©¾3, define sk=inf\{{$\delta$}:there exists 2{$\delta$}n algorithm for solving k-SAT\}. Define ETH (Exponential-Time Hypothesis) for k-SAT as follows: for kâ©¾3, sk{$>$}0. In this paper, we show that sk is increasing infinitely often assuming ETH for k-SAT. Let s{$\infty$} be the limit of sk. We will in fact show that sk{$\leq$}(1-d/k)s{$\infty$} for some constant d{$>$}0. We prove this result by bringing together the ideas of critical clauses and the Sparsification Lemma to reduce the satisfiability of a k-CNF to the satisfiability of a disjunction of 2{$\varepsilon$}nk{$\prime$}-CNFs in fewer variables for some k{$\prime$}â©¾k and arbitrarily small {$\varepsilon>$}0. We also show that such a disjunction can be computed in time 2{$\varepsilon$}n for arbitrarily small {$\varepsilon>$}0.}
}

@book{jerrumCountingSamplingIntegrating2003,
  title = {Counting, {{Sampling}} and {{Integrating}}: {{Algorithm}} and {{Complexity}}},
  shorttitle = {Counting, {{Sampling}} and {{Integrating}}},
  author = {Jerrum, Mark},
  year = {2003},
  publisher = {Birkh{\"a}user Basel},
  doi = {10.1007/978-3-0348-8005-3},
  isbn = {978-3-7643-6946-0 978-3-0348-8005-3}
}

@article{jerrumFastUniformGeneration1990,
  title = {Fast Uniform Generation of Regular Graphs},
  author = {Jerrum, Mark and Sinclair, Alistair},
  year = {1990},
  month = jun,
  journal = {Theoretical Computer Science},
  volume = {73},
  number = {1},
  pages = {91--100},
  issn = {0304-3975},
  doi = {10.1016/0304-3975(90)90164-D},
  abstract = {An algorithm is presented which randomly selects a labelled graph with specified vertex degrees from a distribution which is arbitrarily close to uniform. The algorithm is based on simulation of a rapidly convergent stochastic process, and runs in polynomial time for a wide class of degree sequences, including all regular sequences and all n-vertex sequences with no degree exceeding {\textsurd}n/2. The algorithm can be extended to cover the selection of a graph with given degree sequence which avoids a specified set of edges. One consequence of this extension is the existence of a polynomial-time algorithm for selecting an f-factor in a sufficiently dense graph. A companion algorithm for counting degree-constrained graphs is also presented; this algorithm has exactly the same range of validity as the one for selection.}
}

@article{jerrumPolynomialTimeApproximationAlgorithms1993,
  title = {Polynomial-{{Time Approximation Algorithms}} for the {{Ising Model}}},
  author = {Jerrum, Mark and Sinclair, Alistair},
  year = {1993},
  month = oct,
  journal = {SIAM Journal on Computing},
  volume = {22},
  number = {5},
  pages = {1087--1116},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0097-5397},
  doi = {10.1137/0222066},
  abstract = {A new method for analyzing the mixing time of Markov chains is described. This method is an extension of path coupling and involves analyzing the coupling over multiple steps.The expected behavior of the coupling at a certain stopping time is used to bound the expected behavior of the coupling after a fixed number of steps. The new method is applied to analyze the mixing time of the Glauber dynamics for graph colorings. We show that the Glauber dynamics has O(n log(n)) mixing time for triangle-free \${\textbackslash}Delta\$-regular graphs if k colors are used, where \$k{\textbackslash}geq (2-{\textbackslash}eta){\textbackslash}Delta\$, for some small positive constant \${\textbackslash}eta\$. This is the first proof of an optimal upper bound for the mixing time of the Glauber dynamics for some values of k in the range \$k{\textbackslash}leq 2{\textbackslash}Delta\$.}
}

@article{jerrumRandomGenerationCombinatorial1986,
  title = {Random Generation of Combinatorial Structures from a Uniform Distribution},
  author = {Jerrum, Mark R. and Valiant, Leslie G. and Vazirani, Vijay V.},
  year = {1986},
  month = jan,
  journal = {Theoretical Computer Science},
  volume = {43},
  pages = {169--188},
  issn = {0304-3975},
  doi = {10.1016/0304-3975(86)90174-X},
  abstract = {The class of problems involving the random generation of combinatorial structures from a uniform distribution is considered. Uniform generation problems are, in computational difficulty, intermediate between classical existence and counting problems. It is shown that exactly uniform generation of `efficiently verifiable' combinatorial structures is reducible to approximate counting (and hence, is within the third level of the polynomial hierarchy). Natural combinatorial problems are presented which exhibit complexity gaps between their existence and generation, and between their generation and counting versions. It is further shown that for self-reducible problems, almost uniform generation and randomized approximate counting are inter-reducible, and hence, of similar complexity.}
}

@inproceedings{karpReducibilityCombinatorialProblems1972,
  title = {Reducibility among {{Combinatorial Problems}}},
  booktitle = {Proceedings of a Symposium on the {{Complexity}} of {{Computer Computations}}},
  author = {Karp, Richard M.},
  year = {1972},
  pages = {85--103},
  doi = {10.1007/978-1-4684-2001-2_9},
  abstract = {A large class of computational problems involve the determination of properties of graphs, digraphs, integers, arrays of integers, finite families of finite sets, boolean formulas and elements of other countable domains. Through simple encodings from such domains into the set of words over a finite alphabet these problems can be converted into language recognition problems, and we can inquire into their computational complexity. It is reasonable to consider such a problem satisfactorily solved when an algorithm for its solution is found which terminates within a number of steps bounded by a polynomial in the length of the input. We show that a large number of classic unsolved problems of covering, matching, packing, routing, assignment and sequencing are equivalent, in the sense that either each of them possesses a polynomial-bounded algorithm or none of them does.},
  isbn = {978-1-4684-2001-2}
}

@article{khullerPlanarGraphColoring1991a,
  title = {Planar Graph Coloring Is Not Self-Reducible, Assuming   {{P}}{$\neq$}{{NP}}},
  author = {Khuller, Samir and Vazirani, Vijay V.},
  year = {1991},
  month = oct,
  journal = {Theoretical Computer Science},
  volume = {88},
  number = {1},
  pages = {183},
  issn = {0304-3975},
  doi = {10.1016/0304-3975(91)90081-C}
}

@article{kourtisFastCountingTensor2019,
  title = {Fast Counting with Tensor Networks},
  author = {Kourtis, Stefanos and Chamon, Claudio and Mucciolo, Eduardo and Ruckenstein, Andrei E.},
  year = {2019},
  month = nov,
  journal = {SciPost Physics},
  volume = {7},
  number = {5},
  pages = {060},
  issn = {2542-4653},
  doi = {10.21468/SciPostPhys.7.5.060},
  abstract = {SciPost Journals Publication Detail SciPost Phys. 7, 060 (2019) Fast counting with tensor networks}
}

@article{kromDecisionProblemClass1967,
  title = {The {{Decision Problem}} for a {{Class}} of {{First-Order Formulas}} in {{Which All Disjunctions Are Binary}}},
  author = {Krom, M. R.},
  year = {1967},
  journal = {Zeitschrift fur mathematische Logik und Grundlagen der Mathematik},
  volume = {13},
  number = {1-2},
  pages = {15--20},
  doi = {10.1002/malq.19670130104}
}

@misc{laroccaReviewBarrenPlateaus2024,
  title = {A {{Review}} of {{Barren Plateaus}} in {{Variational Quantum Computing}}},
  author = {Larocca, Martin and Thanasilp, Supanut and Wang, Samson and Sharma, Kunal and Biamonte, Jacob and Coles, Patrick J. and Cincio, Lukasz and McClean, Jarrod R. and Holmes, Zo{\"e} and Cerezo, M.},
  year = {2024},
  month = may,
  number = {arXiv:2405.00781},
  eprint = {2405.00781},
  primaryclass = {quant-ph},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.00781},
  abstract = {Variational quantum computing offers a flexible computational paradigm with applications in diverse areas. However, a key obstacle to realizing their potential is the Barren Plateau (BP) phenomenon. When a model exhibits a BP, its parameter optimization landscape becomes exponentially flat and featureless as the problem size increases. Importantly, all the moving pieces of an algorithm -- choices of ansatz, initial state, observable, loss function and hardware noise -- can lead to BPs when ill-suited. Due to the significant impact of BPs on trainability, researchers have dedicated considerable effort to develop theoretical and heuristic methods to understand and mitigate their effects. As a result, the study of BPs has become a thriving area of research, influencing and cross-fertilizing other fields such as quantum optimal control, tensor networks, and learning theory. This article provides a comprehensive review of the current understanding of the BP phenomenon.},
  archiveprefix = {arXiv}
}

@article{levinUniversalSequentialSearch1973,
  title = {Universal {{Sequential Search Problems}}},
  author = {Levin, Leonid A.},
  year = {1973},
  journal = {Problems of information transmission},
  volume = {9},
  number = {3},
  pages = {256--266},
  abstract = {The article examines several well-known problems of the ``sequential search type'' and proves that these problems can only be solved in the time it takes to solve any problem of the specified type in general.}
}

@misc{lodewijksMappingNPhardNPcomplete2020,
  title = {Mapping {{NP-hard}} and {{NP-complete}} Optimisation Problems to {{Quadratic Unconstrained Binary Optimisation}} Problems},
  author = {Lodewijks, Bas},
  year = {2020},
  month = aug,
  number = {arXiv:1911.08043},
  eprint = {1911.08043},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1911.08043},
  abstract = {We discuss several mappings from well-known NP-hard problems to Quadratic Unconstrained Binary Optimisation problems which are treated incorrectly by Lucas. We provide counterexamples and correct the mappings. We also extend the body of QUBO formulations of NP-complete and NP-hard optimisation problems by discussing additional problems.},
  archiveprefix = {arXiv}
}

@article{lucasIsingFormulationsMany2014,
  title = {Ising Formulations of Many {{NP}} Problems},
  author = {Lucas, Andrew},
  year = {2014},
  month = feb,
  journal = {Frontiers in Physics},
  volume = {2},
  publisher = {Frontiers},
  issn = {2296-424X},
  doi = {10.3389/fphy.2014.00005},
  abstract = {{$<$}p{$>$}We provide Ising formulations for many NP-complete and NP-hard problems, including all of Karp's 21 NP-complete problems. This collects and extends mappings to the Ising model from partitioning, covering, and satisfiability. In each case, the required number of spins is at most cubic in the size of the problem. This work may be useful in designing adiabatic quantum optimization algorithms.{$<$}/p{$>$}}
}

@article{lundHardnessApproximatingMinimization1994,
  title = {On the Hardness of Approximating Minimization Problems},
  author = {Lund, Carsten and Yannakakis, Mihalis},
  year = {1994},
  month = sep,
  journal = {Journal of the ACM},
  volume = {41},
  number = {5},
  pages = {960--981},
  issn = {0004-5411},
  doi = {10.1145/185675.306789}
}

@article{mandraExponentiallyBiasedGroundState2017,
  title = {Exponentially {{Biased Ground-State Sampling}} of {{Quantum Annealing Machines}} with {{Transverse-Field Driving Hamiltonians}}},
  author = {Mandr{\`a}, Salvatore and Zhu, Zheng and Katzgraber, Helmut G.},
  year = {2017},
  month = feb,
  journal = {Physical Review Letters},
  volume = {118},
  number = {7},
  pages = {070502},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.118.070502},
  abstract = {We study the performance of the D-Wave 2X quantum annealing machine on systems with well-controlled ground-state degeneracy. While obtaining the ground state of a spin-glass benchmark instance represents a difficult task, the gold standard for any optimization algorithm or machine is to sample all solutions that minimize the Hamiltonian with more or less equal probability. Our results show that while naive transverse-field quantum annealing on the D-Wave 2X device can find the ground-state energy of the problems, it is not well suited in identifying all degenerate ground-state configurations associated with a particular instance. Even worse, some states are exponentially suppressed, in agreement with previous studies on toy model problems [New J. Phys. 11, 073021 (2009)]. These results suggest that more complex driving Hamiltonians are needed in future quantum annealing machines to ensure a fair sampling of the ground-state manifold.}
}

@inproceedings{marques-silvaPracticalApplicationsBoolean2008,
  title = {Practical Applications of {{Boolean Satisfiability}}},
  booktitle = {2008 9th {{International Workshop}} on {{Discrete Event Systems}}},
  author = {{Marques-Silva}, Joao},
  year = {2008},
  month = may,
  pages = {74--80},
  doi = {10.1109/WODES.2008.4605925},
  abstract = {Boolean satisfiability (SAT) solvers have been the subject of remarkable improvements since the mid 90s. One of the main reasons for these improvements has been the wide range of practical applications of SAT. Indeed, examples of modern applications of SAT range from termination analysis in term-rewrite systems to circuit-level prediction of crosstalk noise. The success of SAT solvers motivated many practical applications, but many practical applications have also provided the examples and the challenges that allowed the development of more efficient SAT solvers. This paper provides an overview of some of the most well-known applications of SAT and outlines several other successful applications of SAT. Moreover, the improvements in SAT solvers motivated the development of new algorithms for strategic extensions of SAT. As a result, the paper also provides a brief survey of recent work on extensions of SAT, including pseudo-Boolean constraints, maximum satisfiability, model counting and quantified Boolean formulas.}
}

@article{matsudaGroundstateStatisticsAnnealing2009,
  title = {Ground-State Statistics from Annealing Algorithms: Quantum versus Classical Approaches},
  shorttitle = {Ground-State Statistics from Annealing Algorithms},
  author = {Matsuda, Yoshiki and Nishimori, Hidetoshi and Katzgraber, Helmut G},
  year = {2009},
  month = jul,
  journal = {New Journal of Physics},
  volume = {11},
  number = {7},
  pages = {073021},
  issn = {1367-2630},
  doi = {10.1088/1367-2630/11/7/073021},
  abstract = {We study the performance of quantum annealing for systems with ground-state degeneracy by directly solving the Schr{\"o}dinger equation for small systems and quantum Monte Carlo simulations for larger systems. The results indicate that naive quantum annealing using a transverse field may not be well suited to identify all degenerate ground-state configurations, although the value of the ground-state energy is often efficiently estimated. An introduction of quantum transitions to all states with equal weights is shown to greatly improve the situation, but with a sacrifice in annealing time. We also clarify the relation between the spin configurations in degenerate ground states and the probabilities that those states are obtained by quantum annealing. The strengths and weaknesses of quantum annealing for problems with degenerate ground states are discussed in comparison with classical simulated annealing.}
}

@article{mccleanBarrenPlateausQuantum2018,
  title = {Barren Plateaus in Quantum Neural Network Training Landscapes},
  author = {McClean, Jarrod R. and Boixo, Sergio and Smelyanskiy, Vadim N. and Babbush, Ryan and Neven, Hartmut},
  year = {2018},
  month = nov,
  journal = {Nature Communications},
  volume = {9},
  number = {1},
  pages = {4812},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-018-07090-4},
  abstract = {Many experimental proposals for noisy intermediate scale quantum devices involve training a parameterized quantum circuit with a classical optimization loop. Such hybrid quantum-classical algorithms are popular for applications in quantum simulation, optimization, and machine learning. Due to its simplicity and hardware efficiency, random circuits are often proposed as initial guesses for exploring the space of quantum states. We show that the exponential dimension of Hilbert space and the gradient estimation complexity make this choice unsuitable for hybrid quantum-classical algorithms run on more than a few qubits. Specifically, we show that for a wide class of reasonable parameterized quantum circuits, the probability that the gradient along any reasonable direction is non-zero to some fixed precision is exponentially small as a function of the number of qubits. We argue that this is related to the 2-design characteristic of random circuits, and that solutions to this problem must be studied.}
}

@book{messiahQuantumMechanics1961,
  title = {Quantum Mechanics},
  author = {Messiah, Albert},
  year = {1961},
  publisher = {North-Holland Publishing Company},
  isbn = {978-0-486-40924-5}
}

@book{mezardInformationPhysicsComputation2009,
  title = {Information, {{Physics}}, and {{Computation}}},
  author = {M{\'e}zard, Marc and Montanari, Andrea},
  year = {2009},
  month = jan,
  publisher = {Oxford University Press},
  url = {https://doi.org/10.1093/acprof:oso/9780198570837.001.0001},
  abstract = {This book presents a unified approach to a rich and rapidly evolving research domain at the interface between statistical physics, theoretical computer science/discrete mathematics, and coding/information theory. The topics which have been selected, including spin glasses, error correcting codes, satisfiability, are central to each field. The approach focuses on the limit of large random instances, adopting a common formulation in terms of graphical models. It presents message passing algorithms like belief propagation and survey propagation, and their use in decoding and constraint satisfaction solving. It also explains analysis techniques like density evolution and the cavity method, and uses them to derive phase diagrams and study phase transitions.},
  isbn = {978-0-19-857083-7}
}

@book{mooreNatureComputation2011,
  title = {The {{Nature Of Computation}}},
  author = {Moore, Cristopher and Mertens, Stephan},
  year = {2011},
  month = aug,
  publisher = {Oxford University Press},
  url = {https://doi.org/10.1093/acprof:oso/9780199233212.001.0001},
  abstract = {Computational complexity is one of the most beautiful fields of modern mathematics, and it is increasingly relevant to other sciences ranging from physics to biology. However, this beauty is often buried underneath layers of unnecessary formalism, and exciting recent results such as interactive proofs, phase transitions, and quantum computing are usually considered too advanced for the typical student. This book bridges these gaps by explaining the deep ideas of theoretical computer science in a clear fashion, making them accessible to non-computer scientists and to computer scientists who finally want to appreciate their field from a new point of view. It starts with a lucid explanation of the P vs. NP problem, explaining why it is so fundamental, and so hard to resolve. It then leads the reader through the complexity of mazes and games; optimisation in theory and practice; randomised algorithms, interactive proofs, and pseudorandomness; Markov chains and phase transitions; and the outer reaches of quantum computing. At every turn, it uses a minimum of formalism, providing explanations that are both deep and accessible.},
  isbn = {978-0-19-923321-2}
}

@book{nielsenQuantumComputationQuantum2011,
  title = {Quantum {{Computation}} and {{Quantum Information}}: 10th {{Anniversary Edition}}},
  shorttitle = {Quantum {{Computation}} and {{Quantum Information}}},
  author = {Nielsen, Michael A. and Chuang, Isaac L.},
  year = {2011},
  publisher = {Cambridge University Press},
  abstract = {One of the most cited books in physics of all time, Quantum Computation and Quantum Information remains the best textbook in this exciting field of science. This 10th anniversary edition includes an introduction from the authors setting the work in context. This comprehensive textbook describes such remarkable effects as fast quantum algorithms, quantum teleportation, quantum cryptography and quantum error-correction. Quantum mechanics and computer science are introduced before moving on to describe what a quantum computer is, how it can be used to solve problems faster than 'classical' computers and its real-world implementation. It concludes with an in-depth treatment of quantum information. Containing a wealth of figures and exercises, this well-known textbook is ideal for courses on the subject, and will interest beginning graduate students and researchers in physics, computer science, mathematics, and electrical engineering.},
  isbn = {978-1-107-00217-3}
}

@article{nishimoriExponentialEnhancementEfficiency2017,
  title = {Exponential {{Enhancement}} of the {{Efficiency}} of {{Quantum Annealing}} by {{Non-Stoquastic Hamiltonians}}},
  author = {Nishimori, Hidetoshi and Takada, Kabuki},
  year = {2017},
  month = feb,
  journal = {Frontiers in ICT},
  volume = {4},
  publisher = {Frontiers},
  issn = {2297-198X},
  doi = {10.3389/fict.2017.00002},
  abstract = {{$<$}p{$>$}Non-stoquastic Hamiltonians have both positive and negative signs in off-diagonal elements in their matrix representation in the standard computational basis and thus cannot be simulated efficiently by the standard quantum Monte Carlo method due to the sign problem. We describe our analytical studies of this type of Hamiltonians with infinite-range non-random as well as random interactions from the perspective of possible enhancement of the efficiency of quantum annealing or adiabatic quantum computing. It is shown that multi-body transverse interactions like {$<$}italic{$>$}XX{$<$}/italic{$>$} and {$<$}italic{$>$}XXXXX{$<$}/italic{$>$} with positive coefficients appended to a stoquastic transverse-field Ising model render the Hamiltonian non-stoquastic and reduce a first-order quantum phase transition in the simple transverse-field case to a second-order transition. This implies that the efficiency of quantum annealing is exponentially enhanced, because a first-order transition has an exponentially small energy gap (and therefore exponentially long computation time) whereas a second-order transition has a polynomially decaying gap (polynomial computation time). The examples presented here represent rare instances where strong quantum effects, in the sense that they cannot be efficiently simulated in the standard quantum Monte Carlo, have analytically been shown to exponentially enhance the efficiency of quantum annealing for combinatorial optimization problems.{$<$}/p{$>$}}
}

@article{ochoaFeedingMultitudePolynomialtime2019,
  title = {Feeding the Multitude: {{A}} Polynomial-Time Algorithm to Improve Sampling},
  shorttitle = {Feeding the Multitude},
  author = {Ochoa, Andrew J. and Jacob, Darryl C. and Mandr{\`a}, Salvatore and Katzgraber, Helmut G.},
  year = {2019},
  month = apr,
  journal = {Physical Review E},
  volume = {99},
  number = {4},
  pages = {043306},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.99.043306},
  abstract = {A wide variety of optimization techniques, both exact and heuristic, tend to be biased samplers. This means that when attempting to find multiple uncorrelated solutions of a degenerate Boolean optimization problem a subset of the solution space tends to be favored while, in the worst case, some solutions can never be accessed by the algorithm used. Here we present a simple postprocessing technique that improves sampling for any optimization approach, either quantum or classical. More precisely, starting from a pool of a few optimal configurations, the algorithm generates potentially new solutions via rejection-free cluster updates at zero temperature. Although the method is not ergodic and there is no guarantee that all the solutions can be found, fair sampling is typically improved. We illustrate the effectiveness of our method by improving the exponentially biased data produced by the D-Wave 2X quantum annealer [S. Mandr{\`a} et al., Phys. Rev. Lett. 118, 070502 (2017)], as well as data from three-dimensional Ising spin glasses. As part of the study, we also show that sampling is improved when suboptimal states are included and discuss sampling at a finite fixed temperature.}
}

@article{raymondPhaseDiagram1in32007,
  title = {Phase Diagram of the 1-in-3 Satisfiability Problem},
  author = {Raymond, Jack and Sportiello, Andrea and Zdeborov{\'a}, Lenka},
  year = {2007},
  month = jul,
  journal = {Physical Review E},
  volume = {76},
  number = {1},
  pages = {011101},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.76.011101},
  abstract = {We study typical case properties of the 1-in-3 satisfiability problem, the Boolean satisfaction problem, where a clause is satisfied by exactly one literal, in an enlarged random ensemble parametrized by average connectivity and probability of negation of a variable in a clause. Random 1-in-3 satisfiability and exact 3-cover are special cases of this ensemble. We interpolate between these cases from a region where satisfiability can be typically decided for all connectivities in polynomial time to a region where deciding satisfiability is hard, in some interval of connectivities. We derive several rigorous results in the first region and develop a one-step replica-symmetry-breaking cavity analysis in the second one. We discuss the prediction for the transition between the almost surely satisfiable and the almost surely unsatisfiable phase, and other structural properties of the phase diagram, in light of cavity method results.}
}

@article{rothHardnessApproximateReasoning1996,
  title = {On the Hardness of Approximate Reasoning},
  author = {Roth, Dan},
  year = {1996},
  month = apr,
  journal = {Artificial Intelligence},
  volume = {82},
  number = {1},
  pages = {273--302},
  issn = {0004-3702},
  doi = {10.1016/0004-3702(94)00092-1},
  abstract = {Many AI problems, when formalized, reduce to evaluating the probability that a propositional expression is true. In this paper we show that this problem is computationally intractable even in surprisingly restricted cases and even if we settle for an approximation to this probability. We consider various methods used in approximate reasoning such as computing degree of belief and Bayesian belief networks, as well as reasoning techniques such as constraint satisfaction and knowledge compilation, that use approximation to avoid computational difficulties, and reduce them to model-counting problems over a propositional domain. We prove that counting satisfying assignments of propositional languages is intractable even for Horn and monotone formulae, and even when the size of clauses and number of occurrences of the variables are extremely limited. This should be contrasted with the case of deductive reasoning, where Horn theories and theories with binary clauses are distinguished by the existence of linear time satisfiability algorithms. What is even more surprising is that, as we show, even approximating the number of satisfying assignments (i.e., ``approximating'' approximate reasoning), is intractable for most of these restricted theories. We also identify some restricted classes of propositional formulae for which efficient algorithms for counting satisfying assignments can be given.}
}

@article{sackQuantumAnnealingInitialization2021,
  title = {Quantum Annealing Initialization of the Quantum Approximate Optimization Algorithm},
  author = {Sack, Stefan H. and Serbyn, Maksym},
  year = {2021},
  month = jul,
  journal = {Quantum},
  volume = {5},
  pages = {491},
  publisher = {Verein zur F{\"o}rderung des Open Access Publizierens in den Quantenwissenschaften},
  doi = {10.22331/q-2021-07-01-491},
  abstract = {Stefan H. Sack and Maksym Serbyn, Quantum 5, 491 (2021). The quantum approximate optimization algorithm (QAOA) is a prospective near-term quantum algorithm due to its modest circuit depth and promising benchmarks. However, an external parameter op{\dots}}
}

@inproceedings{sangPerformingBayesianInference2005,
  title = {Performing {{Bayesian}} Inference by Weighted Model Counting},
  booktitle = {Proceedings of the 20th National Conference on {{Artificial}} Intelligence},
  author = {Sang, Tian and Bearne, Paul and Kautz, Henry},
  year = {2005},
  month = jul,
  volume = {1},
  pages = {475--481},
  abstract = {Over the past decade general satisfiability testing algorithms have proven to be surprisingly effective at solving a wide variety of constraint satisfaction problem, such as planning and scheduling (Kautz and Selman 2003). Solving such NP-complete tasks by "compilation to SAT" has turned out to be an approach that is of both practical and theoretical interest. Recently, (Sang et al. 2004) have shown that state of the art SAT algorithms can be efficiently extended to the harder task of counting the number of models (satisfying assignments) of a formula, by employing a technique called component caching. This paper begins to investigate the question of whether "compilation to model-counting" could be a practical technique for solving real-world \#P-complete problems, in particular Bayesian inference. We describe an efficient translation from Bayesian networks to weighted model counting, extend the best model-counting algorithms to weighted model counting, develop an efficient method for computing all marginals in a single counting pass, and evaluate the approach on computationally challenging reasoning problems.},
  isbn = {978-1-57735-236-5}
}

@inproceedings{schaeferComplexitySatisfiabilityProblems1978,
  title = {The Complexity of Satisfiability Problems},
  booktitle = {Proceedings of the Tenth Annual {{ACM}} Symposium on {{Theory}} of Computing},
  author = {Schaefer, Thomas J.},
  year = {1978},
  month = may,
  pages = {216--226},
  doi = {10.1145/800133.804350},
  abstract = {The problem of deciding whether a given propositional formula in conjunctive normal form is satisfiable has been widely studied. I t is known that, when restricted to formulas having only two literals per clause, this problem has an efficient (polynomial-time) solution. But the same problem on formulas having three literals per clause is NP-complete, and hence probably does not have any efficient solution.In this paper, we consider an infinite class of satisfiability problems which contains these two particular problems as special cases, and show that every member of this class is either polynomial-time decidable or NP-complete. The infinite collection of new NP-complete problems so obtained may prove very useful in finding other new NP-complete problems. The classification of the polynomial-time decidable cases yields new problems that are complete in polynomial time and in nondeterministic log space.We also consider an analogous class of problems, involving quantified formulas, which has the property that every member is either polynomial time decidable or complete in polynomial space.},
  isbn = {978-1-4503-7437-8}
}

@article{schnorrOptimalAlgorithmsSelfReducible1976,
  title = {Optimal {{Algorithms}} for {{Self-Reducible Problems}}},
  author = {Schnorr, Claus-Peter},
  year = {1976},
  journal = {Proccedings of the 3rd International Colloquium on Automata, Languages and Programming},
  volume = {3},
  pages = {322--337},
  issn = {,}
}

@phdthesis{selkeAutoreducibilityFriendsMeasuring2006,
  title = {Autoreducibility and Friends: {{About}} Measuring Redundancy in Sets},
  author = {Selke, Joachim},
  year = {2006},
  school = {Universit{\"a}t Hanover}
}

@inproceedings{sharmaGANAKScalableProbabilistic2019,
  title = {{{GANAK}}: {{A Scalable Probabilistic Exact Model Counter}}},
  shorttitle = {{{GANAK}}},
  booktitle = {Proceedings of the {{Twenty-Eighth International Joint Conference}} on {{Artificial Intelligence}}, {{IJCAI-19}}},
  author = {Sharma, Shubham and Roy, Subhajit and Soos, Mate and Meel, Kuldeep S.},
  year = {2019},
  month = jul,
  pages = {1169--1176},
  doi = {10.24963/ijcai.2019/163},
  abstract = {Electronic proceedings of IJCAI 2019}
}

@inproceedings{shorAlgorithmsQuantumComputation1994,
  title = {Algorithms for Quantum Computation: Discrete Logarithms and Factoring},
  shorttitle = {Algorithms for Quantum Computation},
  booktitle = {Proceedings 35th {{Annual Symposium}} on {{Foundations}} of {{Computer Science}}},
  author = {Shor, P.W.},
  year = {1994},
  month = nov,
  pages = {124--134},
  doi = {10.1109/SFCS.1994.365700},
  abstract = {A computer is generally considered to be a universal computational device; i.e., it is believed able to simulate any physical computational device with a cost in computation time of at most a polynomial factor: It is not clear whether this is still true when quantum mechanics is taken into consideration. Several researchers, starting with David Deutsch, have developed models for quantum mechanical computers and have investigated their computational properties. This paper gives Las Vegas algorithms for finding discrete logarithms and factoring integers on a quantum computer that take a number of steps which is polynomial in the input size, e.g., the number of digits of the integer to be factored. These two problems are generally considered hard on a classical computer and have been used as the basis of several proposed cryptosystems. We thus give the first examples of quantum cryptanalysis.{$<>$}}
}

@book{sinclairAlgorithmsRandomGeneration1993,
  title = {Algorithms for {{Random Generation}} and {{Counting}}: {{A Markov Chain Approach}}},
  shorttitle = {Algorithms for {{Random Generation}} and {{Counting}}},
  author = {Sinclair, Alistair},
  year = {1993},
  publisher = {Birkh{\"a}user},
  doi = {10.1007/978-1-4612-0323-0},
  isbn = {978-1-4612-6707-2 978-1-4612-0323-0}
}

@book{sipserIntroductionTheoryComputation1996,
  title = {Introduction to the {{Theory}} of {{Computation}}},
  author = {Sipser, Michael},
  year = {1996},
  month = nov,
  edition = {1},
  publisher = {International Thomson Publishing},
  abstract = {From the Publisher:Michael Sipser's philosophy in writing this book is simple: make the subject interesting and relevant, and the students will learn. His emphasis on unifying computer science theory - rather than offering a collection of low-level details - sets the book apart, as do his intuitive explanations. Throughout the book, Sipser - a noted authority on the theory of computation - builds students' knowledge of conceptual tools used in computer science, the aesthetic sense they need to create elegant systems, and the ability to think through problems on their own. INTRODUCTION TO THE THEORY OF COMPUTATION provides a mathematical treatment of computation theory grounded in theorems and proofs. Proofs are presented with a "proof idea" component to reveal the concepts underpinning the formalism. Algorithms are presented using prose instead of pseudocode to focus attention on the algorithms themselves, rather than on specific computational models. Topic coverage, terminology, and order of presentation are traditional for an upper-level course in computer science theory. Users of the Preliminary Edition (now out of print) will be interested to note several new chapters on complexity theory: Chapter 8 on space complexity; Chapter 9 on provable intractability, and Chapter 10 on advanced topics, including approximation algorithms, alternation, interactive proof systems, cryptography, and parallel computing.},
  isbn = {978-0-534-94728-6}
}

@inproceedings{stockmeyerComplexityApproximateCounting1983,
  title = {The Complexity of Approximate Counting},
  booktitle = {Proceedings of the Fifteenth Annual {{ACM}} Symposium on {{Theory}} of Computing},
  author = {Stockmeyer, Larry},
  year = {1983},
  month = dec,
  pages = {118--126},
  doi = {10.1145/800061.808740},
  abstract = {There are several computational problems that can be formulated as problems of counting the number of objects having a certain property. Valiant [22] has introduced the class \#P which includes a variety of counting problems such as counting the number of perfect matchings in a graph, computing the permanent of a matrix [22], finding the size of a backtrack search tree [14], and computing the probability that a network remains connected when links can fail with a certain probability [23].We define and study a class of restricted, but very natural, probabilistic sampling methods motivated by the particular counting problems mentioned above. Instead of ``singleton sampling'' the algorithm is allowed to sample a large set S ample; U in one step; the information returned from the sample is whether S contains any element having the property being counted.We attempt to classify the complexity of computing approximate solutions to problems in \#P. The classification is done in terms of the polynomial-time hierarchy (for short, P-hierarchy) [21].We give a relativization result that complements a recent result of Sipser and Gaacute;c [19] that BPP is contained in the second level of the P-hierarchy.},
  isbn = {978-0-89791-099-6}
}

@misc{sundarQuantumAlgorithmCount2019,
  title = {A Quantum Algorithm to Count Weighted Ground States of Classical Spin {{Hamiltonians}}},
  author = {Sundar, Bhuvanesh and Paredes, Roger and Damanik, David T. and {Due{\~n}as-Osorio}, Leonardo and Hazzard, Kaden R. A.},
  year = {2019},
  month = aug,
  number = {arXiv:1908.01745},
  eprint = {1908.01745},
  primaryclass = {quant-ph},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1908.01745},
  abstract = {Ground state counting plays an important role in several applications in science and engineering, from estimating residual entropy in physical systems, to bounding engineering reliability and solving combinatorial counting problems. While quantum algorithms such as adiabatic quantum optimization (AQO) and quantum approximate optimization (QAOA) can minimize Hamiltonians, they are inadequate for counting ground states. We modify AQO and QAOA to count the ground states of arbitrary classical spin Hamiltonians, including counting ground states with arbitrary nonnegative weights attached to them. As a concrete example, we show how our method can be used to count the weighted fraction of edge covers on graphs, with user-specified confidence on the relative error of the weighted count, in the asymptotic limit of large graphs. We find the asymptotic computational time complexity of our algorithms, via analytical predictions for AQO and numerical calculations for QAOA, and compare with the classical optimal Monte Carlo algorithm (OMCS), as well as a modified Grover's algorithm. We show that for large problem instances with small weights on the ground states, AQO does not have a quantum speedup over OMCS for a fixed error and confidence, but QAOA has a sub-quadratic speedup on a broad class of numerically simulated problems. Our work is an important step in approaching general ground-state counting problems beyond those that can be solved with Grover's algorithm. It offers algorithms that can employ noisy intermediate-scale quantum devices for solving ground state counting problems on small instances, which can help in identifying more problem classes with quantum speedups.},
  archiveprefix = {arXiv}
}

@article{timmeCountingComplexDisordered2009,
  title = {Counting Complex Disordered States by Efficient Pattern Matching: Chromatic Polynomials and {{Potts}} Partition Functions},
  shorttitle = {Counting Complex Disordered States by Efficient Pattern Matching},
  author = {Timme, Marc and {van Bussel}, Frank and Fliegner, Denny and Stolzenberg, Sebastian},
  year = {2009},
  month = feb,
  journal = {New Journal of Physics},
  volume = {11},
  number = {2},
  pages = {023001},
  issn = {1367-2630},
  doi = {10.1088/1367-2630/11/2/023001},
  abstract = {Counting problems, determining the number of possible states of a large system under certain constraints, play an important role in many areas of science. They naturally arise for complex disordered systems in physics and chemistry, in mathematical graph theory, and in computer science. Counting problems, however, are among the hardest problems to access computationally. Here, we suggest a novel method to access a benchmark counting problem, finding chromatic polynomials of graphs. We develop a vertex-oriented symbolic pattern matching algorithm that exploits the equivalence between the chromatic polynomial and the zero-temperature partition function of the Potts antiferromagnet on the same graph. Implementing this bottom-up algorithm using appropriate computer algebra, the new method outperforms standard top-down methods by several orders of magnitude, already for moderately sized graphs. As a first application, we compute chromatic polynomials of samples of the simple cubic lattice, for the first time computationally accessing three-dimensional lattices of physical relevance. The method offers straightforward generalizations to several other counting problems.}
}

@article{todaPPHardPolynomialTime1991,
  title = {{{PP}} Is as {{Hard}} as the {{Polynomial-Time Hierarchy}}},
  author = {Toda, Seinosuke},
  year = {1991},
  month = oct,
  journal = {SIAM Journal on Computing},
  volume = {20},
  number = {5},
  pages = {865--877},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0097-5397},
  doi = {10.1137/0220053},
  abstract = {In this paper, it is shown that many natural counting classes, such as PP, \$C\_ =  P\$, and \$\{{\textbackslash}text\{MOD\}\}\_k \{{\textbackslash}text\{P\}\}\$, are at least as computationally hard as PH (the polynomial-time hierarchy) in the following sense: for each \$\{{\textbackslash}bf K\}\$ of the counting classes above, every set in \$\{{\textbackslash}bf K\}\$(PH) is polynomial-time randomized many-one reducible to a set in \$\{{\textbackslash}bf K\}\$ with two-sided exponentially small error probability. As a consequence of the result, it is seen that all the counting classes above are computationally harder than PH unless PH collapses to a finite level. Some other consequences are also shown.}
}

@inproceedings{trakhtenbrotAutoreducibility1970,
  title = {On Autoreducibility},
  booktitle = {Doklady {{Akademii Nauk}}},
  author = {Trakhtenbrot, Boris Avraamovich},
  year = {1970},
  volume = {192},
  pages = {1224--1227}
}

@article{valiantComplexityComputingPermanent1979,
  title = {The Complexity of Computing the Permanent},
  author = {Valiant, L. G.},
  year = {1979},
  month = jan,
  journal = {Theoretical Computer Science},
  volume = {8},
  number = {2},
  pages = {189--201},
  issn = {0304-3975},
  doi = {10.1016/0304-3975(79)90044-6},
  abstract = {It is shown that the permanent function of (0, 1)-matrices is a complete problem for the class of counting problems associated with nondeterministic polynomial time computations. Related counting problems are also considered. The reductions used are characterized by their nontrivial use of arithmetic.}
}

@article{valiantComplexityEnumerationReliability1979,
  title = {The {{Complexity}} of {{Enumeration}} and {{Reliability Problems}}},
  author = {Valiant, Leslie G.},
  year = {1979},
  month = aug,
  journal = {SIAM Journal on Computing},
  volume = {8},
  number = {3},
  pages = {410--421},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0097-5397},
  doi = {10.1137/0208032},
  abstract = {In this paper we show that a generalization of a popular motion planning puzzle called Lunar Lockout is computationally intractable. In particular, we show that the problem is PSPACE-complete. We begin with a review of NP-completeness and polynomial-time reductions, introduce the class PSPACE, and motivate the significance of PSPACE-complete problems. Afterwards, we prove that determining whether a given instance of a generalized Lunar Lockout puzzle is solvable is PSPACE-complete.}
}

@book{vaziraniApproximationAlgorithms2003,
  title = {Approximation {{Algorithms}}},
  author = {Vazirani, Vijay V.},
  year = {2003},
  publisher = {Springer},
  doi = {10.1007/978-3-662-04565-7},
  isbn = {978-3-642-08469-0 978-3-662-04565-7}
}

@inproceedings{vigerEfficientSimpleGeneration2005,
  title = {Efficient and {{Simple Generation}} of {{Random Simple Connected Graphs}} with {{Prescribed Degree Sequence}}},
  booktitle = {Computing and {{Combinatorics}}},
  author = {Viger, Fabien and Latapy, Matthieu},
  year = {2005},
  pages = {440--449},
  doi = {10.1007/11533719_45},
  abstract = {We address here the problem of generating random graphs uniformly from the set of simple connected graphs having a prescribed degree sequence. Our goal is to provide an algorithm designed for practical use both because of its ability to generate very large graphs (efficiency) and because it is easy to implement (simplicity).},
  isbn = {978-3-540-31806-4}
}

@article{virtanenSciPy10Fundamental2020,
  title = {{{SciPy}} 1.0: Fundamental Algorithms for Scientific Computing in {{Python}}},
  shorttitle = {{{SciPy}} 1.0},
  author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and {van der Walt}, St{\'e}fan J. and Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and Kern, Robert and Larson, Eric and Carey, C. J. and Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and VanderPlas, Jake and Laxalde, Denis and Perktold, Josef and Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and Harris, Charles R. and Archibald, Anne M. and Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and {van Mulbregt}, Paul},
  year = {2020},
  month = mar,
  journal = {Nature Methods},
  volume = {17},
  number = {3},
  pages = {261--272},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/s41592-019-0686-2},
  abstract = {SciPy is an open-source scientific computing library for the Python programming language. Since its initial release in 2001, SciPy has become a de facto standard for leveraging scientific algorithms in Python, with over 600 unique code contributors, thousands of dependent packages, over 100,000 dependent repositories and millions of downloads per year. In this work, we provide an overview of the capabilities and development practices of SciPy 1.0 and highlight some recent technical developments.}
}

@inproceedings{wahlstromTighterBoundCounting2008a,
  title = {A {{Tighter Bound}} for {{Counting Max-Weight Solutions}} to {{2SAT Instances}}},
  booktitle = {Parameterized and {{Exact Computation}}},
  author = {Wahlstr{\"o}m, Magnus},
  editor = {Grohe, Martin and Niedermeier, Rolf},
  year = {2008},
  pages = {202--213},
  doi = {10.1007/978-3-540-79723-4_19},
  abstract = {We give an algorithm for counting the number of max-weight solutions to a 2SAT formula, and improve the bound on its running time to . The main source of the improvement is a refinement of the method of analysis, where we extend the concept of compound (piecewise linear) measures to multivariate measures, also allowing the optimal parameters for the measure to be found automatically. This method extension should be of independent interest.},
  isbn = {978-3-540-79723-4}
}

@article{wieSimplerQuantumCounting2019,
  title = {Simpler Quantum Counting},
  author = {Wie, Chu-Ryang},
  year = {2019},
  month = sep,
  journal = {Quantum Information and Computation},
  volume = {19},
  number = {11 \& 12},
  pages = {0967--0983},
  publisher = {Rinton Press},
  issn = {1533-7146},
  doi = {10.26421/QIC19.11-12-5}
}

@article{wurtzCounterdiabaticityQuantumApproximate2022,
  title = {Counterdiabaticity and the Quantum Approximate Optimization Algorithm},
  author = {Wurtz, Jonathan and Love, Peter J.},
  year = {2022},
  month = jan,
  journal = {Quantum},
  volume = {6},
  pages = {635},
  publisher = {Verein zur F{\"o}rderung des Open Access Publizierens in den Quantenwissenschaften},
  doi = {10.22331/q-2022-01-27-635},
  abstract = {Jonathan Wurtz and Peter J. Love, Quantum 6, 635 (2022). The quantum approximate optimization algorithm (QAOA) is a near-term hybrid algorithm intended to solve combinatorial optimization problems, such as MaxCut. QAOA can be made to mimic an adia{\dots}}
}

@article{xiePerformanceUpperBound2025,
  title = {Performance Upper Bound of a {{Grover-mixer}} Quantum Alternating Operator Ansatz},
  author = {Xie, Ningyi and Xu, Jiahua and Chen, Tiejin and Lee, Xinwei and Saito, Yoshiyuki and Asai, Nobuyoshi and Cai, Dongsheng},
  year = {2025},
  month = jan,
  journal = {Physical Review A},
  volume = {111},
  number = {1},
  pages = {012401},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevA.111.012401},
  abstract = {The quantum alternating operator ansatz (QAOA) represents a branch of quantum algorithms for solving combinatorial optimization problems. A specific variant, the Grover-mixer (GM) QAOA, ensures uniform amplitude across states that share equivalent objective values. This property makes the algorithm independent of the problem structure, focusing instead on the distribution of objective values within the problem. In this work we provide an alternative proof for the upper bound on the probability of measuring a computational basis state from a GM QAOA circuit with a given depth, which is a critical factor in QAOA cost. Using this, we derive the upper bounds for the probability of sampling an optimal solution and for the approximation ratio of maximum optimization problems, both dependent on the objective value distribution. Through numerical analysis, we link the distribution to the problem size and build the regression models that relate the problem size, QAOA depth, and performance upper bound. Our results suggest that the GM QAOA provides a quadratic enhancement in sampling probability and requires circuit depth that scales exponentially with problem size to maintain consistent performance.}
}

@misc{zdeborovaStatisticalPhysicsHard2008,
  title = {Statistical {{Physics}} of {{Hard Optimization Problems}}},
  author = {Zdeborov{\'a}, Lenka},
  year = {2008},
  month = jun,
  number = {arXiv:0806.4112},
  eprint = {0806.4112},
  primaryclass = {cond-mat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.0806.4112},
  abstract = {Optimization is fundamental in many areas of science, from computer science and information theory to engineering and statistical physics, as well as to biology or social sciences. It typically involves a large number of variables and a cost function depending on these variables. Optimization problems in the NP-complete class are particularly difficult, it is believed that the number of operations required to minimize the cost function is in the most difficult cases exponential in the system size. However, even in an NP-complete problem the practically arising instances might, in fact, be easy to solve. The principal question we address in this thesis is: How to recognize if an NP-complete constraint satisfaction problem is typically hard and what are the main reasons for this? We adopt approaches from the statistical physics of disordered systems, in particular the cavity method developed originally to describe glassy systems. We describe new properties of the space of solutions in two of the most studied constraint satisfaction problems - random satisfiability and random graph coloring. We suggest a relation between the existence of the so-called frozen variables and the algorithmic hardness of a problem. Based on these insights, we introduce a new class of problems which we named "locked" constraint satisfaction, where the statistical description is easily solvable, but from the algorithmic point of view they are even more challenging than the canonical satisfiability.},
  archiveprefix = {arXiv}
}

@article{zhouQuantumApproximateOptimization2020,
  title = {Quantum {{Approximate Optimization Algorithm}}: {{Performance}}, {{Mechanism}}, and {{Implementation}} on {{Near-Term Devices}}},
  author = {Zhou, Leo and Wang, Sheng-Tao and Choi, Soonwon and Pichler, Hannes and Lukin, Mikhail D.},
  year = {2020},
  month = jun,
  journal = {Physical Review X},
  volume = {10},
  number = {2},
  pages = {021067},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevX.10.021067},
  abstract = {The quantum approximate optimization algorithm (QAOA) is a hybrid quantum-classical variational algorithm designed to tackle combinatorial optimization problems. Despite its promise for near-term quantum applications, not much is currently understood about the QAOA's performance beyond its lowest-depth variant. An essential but missing ingredient for understanding and deploying the QAOA is a constructive approach to carry out the outer-loop classical optimization. We provide an in-depth study of the performance of the QAOA on MaxCut problems by developing an efficient parameter-optimization procedure and revealing its ability to exploit nonadiabatic operations. Building on observed patterns in optimal parameters, we propose heuristic strategies for initializing optimizations to find quasioptimal {$p$}-level QAOA parameters in {$O$}â¡[polyâ¡({$p$})] time, whereas the standard strategy of random initialization requires 2{$O$}â¡({$p$}) optimization runs to achieve similar performance. We then benchmark the QAOA and compare it with quantum annealing, especially on difficult instances where adiabatic quantum annealing fails due to small spectral gaps. The comparison reveals that the QAOA can learn via optimization to utilize nonadiabatic mechanisms to circumvent the challenges associated with vanishing spectral gaps. Finally, we provide a realistic resource analysis on the experimental implementation of the QAOA. When quantum fluctuations in measurements are accounted for, we illustrate that optimization is important only for problem sizes beyond numerical simulations but accessible on near-term devices. We propose a feasible implementation of large MaxCut problems with a few hundred vertices in a system of 2D neutral atoms, reaching the regime to challenge the best classical algorithms.},
}